{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quantum-Enhanced LSTM Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One field that so far has been poorly explored in Quantum Machine Learning is Natural Language Processing (NLP), the sub-field of Artificial Intelligence that gives computers the ability to read, write and to some extent comprehend written text. \n",
    "\n",
    "As documents are usually presented as sequences of words, historically one of the most successful techniques to manipulate this kind of data has been the Recurrent Neural Network architecture, and in particular a variant called Long Short-Term Memory (LSTM). LSTMs allowed machines to perform translations, classification and intent detection with state-of-the-art accuracy until the advent of Transformer networks. Still, it’s interesting at least from an educational point of view to dig into LSTMs to see what good quantum computing may bring to the field. For a more thorough discussion, please refer to “Quantum Long Short-Term Memory” by Chen, Yoo and Fang (arXiv:2009.01783) and “Recurrent Quantum Neural Networks” by J. Bausch (arXiv:2006.14619)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cpb5867\\Anaconda3\\envs\\QLSTM\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from qlstm_pennylane import QLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the possible tags: determinant, noun, verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}  # Assign each tag with a unique index\n",
    "ix_to_tag = {i:k for k,i in tag_to_ix.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below tokenizes the sentence and matches the label to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can prepare the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n",
      "Entities: {0: 'DET', 1: 'NN', 2: 'V'}\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    # Tags are: DET - determiner; NN - noun; V - verb\n",
    "    # For example, the word \"The\" is a determiner\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "\n",
    "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
    "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
    "\n",
    "print(f\"Vocabulary: {word_to_ix}\")\n",
    "print(f\"Entities: {ix_to_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to pass the two sequences through the LSTM, which will output the hidden array of vectors [h_0, h_1, h_2, h_3, h_4], one for each word. A dense layer “head” is attached to the LSTM’s outputs to calculate the probability that each word may be a determinant, noun or verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, n_qubits=0):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        if n_qubits > 0:\n",
    "            print(\"Tagger will use Quantum LSTM\")\n",
    "            self.lstm = QLSTM(embedding_dim, hidden_dim, n_qubits=n_qubits)\n",
    "        else:\n",
    "            print(\"Tagger will use Classical LSTM\")\n",
    "            self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_logits = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_logits, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 8\n",
    "hidden_dim = 6\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger will use Classical LSTM\n"
     ]
    }
   ],
   "source": [
    "model_classical = LSTMTagger(embedding_dim, \n",
    "                        hidden_dim, \n",
    "                        vocab_size=len(word_to_ix), \n",
    "                        tagset_size=len(tag_to_ix), \n",
    "                        n_qubits=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example from the PyTorch website, we train the two networks (classical and quantum LSTM) for 300 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epochs):\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    history = {\n",
    "        'loss': [],\n",
    "        'acc': []\n",
    "    }\n",
    "    for epoch in range(n_epochs):\n",
    "        losses = []\n",
    "        preds = []\n",
    "        targets = []\n",
    "        for sentence, tags in training_data:\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "            labels = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            tag_scores = model(sentence_in)\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            loss = loss_function(tag_scores, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(float(loss))\n",
    "            \n",
    "            probs = torch.softmax(tag_scores, dim=-1)\n",
    "            preds.append(probs.argmax(dim=-1))\n",
    "            targets.append(labels)\n",
    "\n",
    "        avg_loss = np.mean(losses)\n",
    "        history['loss'].append(avg_loss)\n",
    "        \n",
    "        preds = torch.cat(preds)\n",
    "        targets = torch.cat(targets)\n",
    "        corrects = (preds == targets)\n",
    "        accuracy = corrects.sum().float() / float(targets.size(0) )\n",
    "        history['acc'].append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} / {n_epochs}: Loss = {avg_loss:.3f} Acc = {accuracy:.2f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 300: Loss = 1.083 Acc = 0.44\n",
      "Epoch 2 / 300: Loss = 1.079 Acc = 0.44\n",
      "Epoch 3 / 300: Loss = 1.074 Acc = 0.44\n",
      "Epoch 4 / 300: Loss = 1.070 Acc = 0.44\n",
      "Epoch 5 / 300: Loss = 1.065 Acc = 0.44\n",
      "Epoch 6 / 300: Loss = 1.061 Acc = 0.44\n",
      "Epoch 7 / 300: Loss = 1.057 Acc = 0.44\n",
      "Epoch 8 / 300: Loss = 1.053 Acc = 0.44\n",
      "Epoch 9 / 300: Loss = 1.049 Acc = 0.44\n",
      "Epoch 10 / 300: Loss = 1.045 Acc = 0.44\n",
      "Epoch 11 / 300: Loss = 1.040 Acc = 0.44\n",
      "Epoch 12 / 300: Loss = 1.036 Acc = 0.44\n",
      "Epoch 13 / 300: Loss = 1.032 Acc = 0.44\n",
      "Epoch 14 / 300: Loss = 1.028 Acc = 0.44\n",
      "Epoch 15 / 300: Loss = 1.024 Acc = 0.44\n",
      "Epoch 16 / 300: Loss = 1.020 Acc = 0.44\n",
      "Epoch 17 / 300: Loss = 1.016 Acc = 0.44\n",
      "Epoch 18 / 300: Loss = 1.012 Acc = 0.44\n",
      "Epoch 19 / 300: Loss = 1.007 Acc = 0.44\n",
      "Epoch 20 / 300: Loss = 1.003 Acc = 0.44\n",
      "Epoch 21 / 300: Loss = 0.999 Acc = 0.44\n",
      "Epoch 22 / 300: Loss = 0.994 Acc = 0.44\n",
      "Epoch 23 / 300: Loss = 0.990 Acc = 0.44\n",
      "Epoch 24 / 300: Loss = 0.985 Acc = 0.44\n",
      "Epoch 25 / 300: Loss = 0.981 Acc = 0.44\n",
      "Epoch 26 / 300: Loss = 0.976 Acc = 0.44\n",
      "Epoch 27 / 300: Loss = 0.971 Acc = 0.44\n",
      "Epoch 28 / 300: Loss = 0.967 Acc = 0.44\n",
      "Epoch 29 / 300: Loss = 0.962 Acc = 0.44\n",
      "Epoch 30 / 300: Loss = 0.957 Acc = 0.44\n",
      "Epoch 31 / 300: Loss = 0.952 Acc = 0.44\n",
      "Epoch 32 / 300: Loss = 0.947 Acc = 0.44\n",
      "Epoch 33 / 300: Loss = 0.941 Acc = 0.44\n",
      "Epoch 34 / 300: Loss = 0.936 Acc = 0.44\n",
      "Epoch 35 / 300: Loss = 0.931 Acc = 0.56\n",
      "Epoch 36 / 300: Loss = 0.925 Acc = 0.56\n",
      "Epoch 37 / 300: Loss = 0.920 Acc = 0.56\n",
      "Epoch 38 / 300: Loss = 0.914 Acc = 0.56\n",
      "Epoch 39 / 300: Loss = 0.908 Acc = 0.56\n",
      "Epoch 40 / 300: Loss = 0.902 Acc = 0.56\n",
      "Epoch 41 / 300: Loss = 0.896 Acc = 0.56\n",
      "Epoch 42 / 300: Loss = 0.890 Acc = 0.56\n",
      "Epoch 43 / 300: Loss = 0.884 Acc = 0.56\n",
      "Epoch 44 / 300: Loss = 0.878 Acc = 0.56\n",
      "Epoch 45 / 300: Loss = 0.872 Acc = 0.56\n",
      "Epoch 46 / 300: Loss = 0.866 Acc = 0.56\n",
      "Epoch 47 / 300: Loss = 0.859 Acc = 0.56\n",
      "Epoch 48 / 300: Loss = 0.853 Acc = 0.56\n",
      "Epoch 49 / 300: Loss = 0.846 Acc = 0.56\n",
      "Epoch 50 / 300: Loss = 0.840 Acc = 0.67\n",
      "Epoch 51 / 300: Loss = 0.833 Acc = 0.67\n",
      "Epoch 52 / 300: Loss = 0.826 Acc = 0.78\n",
      "Epoch 53 / 300: Loss = 0.819 Acc = 0.78\n",
      "Epoch 54 / 300: Loss = 0.812 Acc = 0.78\n",
      "Epoch 55 / 300: Loss = 0.805 Acc = 0.78\n",
      "Epoch 56 / 300: Loss = 0.798 Acc = 0.78\n",
      "Epoch 57 / 300: Loss = 0.791 Acc = 0.78\n",
      "Epoch 58 / 300: Loss = 0.784 Acc = 0.78\n",
      "Epoch 59 / 300: Loss = 0.777 Acc = 0.78\n",
      "Epoch 60 / 300: Loss = 0.769 Acc = 0.78\n",
      "Epoch 61 / 300: Loss = 0.762 Acc = 0.78\n",
      "Epoch 62 / 300: Loss = 0.754 Acc = 0.78\n",
      "Epoch 63 / 300: Loss = 0.747 Acc = 0.78\n",
      "Epoch 64 / 300: Loss = 0.739 Acc = 0.78\n",
      "Epoch 65 / 300: Loss = 0.732 Acc = 0.78\n",
      "Epoch 66 / 300: Loss = 0.724 Acc = 0.78\n",
      "Epoch 67 / 300: Loss = 0.716 Acc = 0.78\n",
      "Epoch 68 / 300: Loss = 0.709 Acc = 0.78\n",
      "Epoch 69 / 300: Loss = 0.701 Acc = 0.78\n",
      "Epoch 70 / 300: Loss = 0.693 Acc = 0.78\n",
      "Epoch 71 / 300: Loss = 0.685 Acc = 0.78\n",
      "Epoch 72 / 300: Loss = 0.677 Acc = 0.78\n",
      "Epoch 73 / 300: Loss = 0.670 Acc = 0.78\n",
      "Epoch 74 / 300: Loss = 0.662 Acc = 0.78\n",
      "Epoch 75 / 300: Loss = 0.654 Acc = 0.89\n",
      "Epoch 76 / 300: Loss = 0.646 Acc = 0.89\n",
      "Epoch 77 / 300: Loss = 0.638 Acc = 0.89\n",
      "Epoch 78 / 300: Loss = 0.630 Acc = 0.89\n",
      "Epoch 79 / 300: Loss = 0.622 Acc = 0.89\n",
      "Epoch 80 / 300: Loss = 0.614 Acc = 0.89\n",
      "Epoch 81 / 300: Loss = 0.606 Acc = 0.89\n",
      "Epoch 82 / 300: Loss = 0.598 Acc = 0.89\n",
      "Epoch 83 / 300: Loss = 0.591 Acc = 0.89\n",
      "Epoch 84 / 300: Loss = 0.583 Acc = 0.89\n",
      "Epoch 85 / 300: Loss = 0.575 Acc = 0.89\n",
      "Epoch 86 / 300: Loss = 0.567 Acc = 0.89\n",
      "Epoch 87 / 300: Loss = 0.560 Acc = 0.89\n",
      "Epoch 88 / 300: Loss = 0.552 Acc = 0.89\n",
      "Epoch 89 / 300: Loss = 0.545 Acc = 0.89\n",
      "Epoch 90 / 300: Loss = 0.537 Acc = 0.89\n",
      "Epoch 91 / 300: Loss = 0.530 Acc = 0.89\n",
      "Epoch 92 / 300: Loss = 0.522 Acc = 0.89\n",
      "Epoch 93 / 300: Loss = 0.515 Acc = 0.89\n",
      "Epoch 94 / 300: Loss = 0.508 Acc = 0.89\n",
      "Epoch 95 / 300: Loss = 0.501 Acc = 0.89\n",
      "Epoch 96 / 300: Loss = 0.494 Acc = 0.89\n",
      "Epoch 97 / 300: Loss = 0.487 Acc = 0.89\n",
      "Epoch 98 / 300: Loss = 0.480 Acc = 0.89\n",
      "Epoch 99 / 300: Loss = 0.474 Acc = 0.89\n",
      "Epoch 100 / 300: Loss = 0.467 Acc = 0.89\n",
      "Epoch 101 / 300: Loss = 0.461 Acc = 0.89\n",
      "Epoch 102 / 300: Loss = 0.454 Acc = 0.89\n",
      "Epoch 103 / 300: Loss = 0.448 Acc = 0.89\n",
      "Epoch 104 / 300: Loss = 0.442 Acc = 0.89\n",
      "Epoch 105 / 300: Loss = 0.436 Acc = 0.78\n",
      "Epoch 106 / 300: Loss = 0.430 Acc = 0.78\n",
      "Epoch 107 / 300: Loss = 0.424 Acc = 0.78\n",
      "Epoch 108 / 300: Loss = 0.418 Acc = 0.78\n",
      "Epoch 109 / 300: Loss = 0.412 Acc = 0.78\n",
      "Epoch 110 / 300: Loss = 0.407 Acc = 0.78\n",
      "Epoch 111 / 300: Loss = 0.401 Acc = 0.78\n",
      "Epoch 112 / 300: Loss = 0.396 Acc = 0.78\n",
      "Epoch 113 / 300: Loss = 0.390 Acc = 0.78\n",
      "Epoch 114 / 300: Loss = 0.385 Acc = 0.78\n",
      "Epoch 115 / 300: Loss = 0.380 Acc = 0.78\n",
      "Epoch 116 / 300: Loss = 0.375 Acc = 0.89\n",
      "Epoch 117 / 300: Loss = 0.370 Acc = 0.89\n",
      "Epoch 118 / 300: Loss = 0.365 Acc = 0.89\n",
      "Epoch 119 / 300: Loss = 0.360 Acc = 0.89\n",
      "Epoch 120 / 300: Loss = 0.355 Acc = 0.89\n",
      "Epoch 121 / 300: Loss = 0.350 Acc = 0.89\n",
      "Epoch 122 / 300: Loss = 0.346 Acc = 1.00\n",
      "Epoch 123 / 300: Loss = 0.341 Acc = 1.00\n",
      "Epoch 124 / 300: Loss = 0.337 Acc = 1.00\n",
      "Epoch 125 / 300: Loss = 0.332 Acc = 1.00\n",
      "Epoch 126 / 300: Loss = 0.328 Acc = 1.00\n",
      "Epoch 127 / 300: Loss = 0.323 Acc = 1.00\n",
      "Epoch 128 / 300: Loss = 0.319 Acc = 1.00\n",
      "Epoch 129 / 300: Loss = 0.315 Acc = 1.00\n",
      "Epoch 130 / 300: Loss = 0.311 Acc = 1.00\n",
      "Epoch 131 / 300: Loss = 0.306 Acc = 1.00\n",
      "Epoch 132 / 300: Loss = 0.302 Acc = 1.00\n",
      "Epoch 133 / 300: Loss = 0.298 Acc = 1.00\n",
      "Epoch 134 / 300: Loss = 0.294 Acc = 1.00\n",
      "Epoch 135 / 300: Loss = 0.290 Acc = 1.00\n",
      "Epoch 136 / 300: Loss = 0.286 Acc = 1.00\n",
      "Epoch 137 / 300: Loss = 0.283 Acc = 1.00\n",
      "Epoch 138 / 300: Loss = 0.279 Acc = 1.00\n",
      "Epoch 139 / 300: Loss = 0.275 Acc = 1.00\n",
      "Epoch 140 / 300: Loss = 0.271 Acc = 1.00\n",
      "Epoch 141 / 300: Loss = 0.268 Acc = 1.00\n",
      "Epoch 142 / 300: Loss = 0.264 Acc = 1.00\n",
      "Epoch 143 / 300: Loss = 0.260 Acc = 1.00\n",
      "Epoch 144 / 300: Loss = 0.257 Acc = 1.00\n",
      "Epoch 145 / 300: Loss = 0.253 Acc = 1.00\n",
      "Epoch 146 / 300: Loss = 0.250 Acc = 1.00\n",
      "Epoch 147 / 300: Loss = 0.246 Acc = 1.00\n",
      "Epoch 148 / 300: Loss = 0.243 Acc = 1.00\n",
      "Epoch 149 / 300: Loss = 0.240 Acc = 1.00\n",
      "Epoch 150 / 300: Loss = 0.237 Acc = 1.00\n",
      "Epoch 151 / 300: Loss = 0.233 Acc = 1.00\n",
      "Epoch 152 / 300: Loss = 0.230 Acc = 1.00\n",
      "Epoch 153 / 300: Loss = 0.227 Acc = 1.00\n",
      "Epoch 154 / 300: Loss = 0.224 Acc = 1.00\n",
      "Epoch 155 / 300: Loss = 0.221 Acc = 1.00\n",
      "Epoch 156 / 300: Loss = 0.218 Acc = 1.00\n",
      "Epoch 157 / 300: Loss = 0.215 Acc = 1.00\n",
      "Epoch 158 / 300: Loss = 0.212 Acc = 1.00\n",
      "Epoch 159 / 300: Loss = 0.209 Acc = 1.00\n",
      "Epoch 160 / 300: Loss = 0.206 Acc = 1.00\n",
      "Epoch 161 / 300: Loss = 0.204 Acc = 1.00\n",
      "Epoch 162 / 300: Loss = 0.201 Acc = 1.00\n",
      "Epoch 163 / 300: Loss = 0.198 Acc = 1.00\n",
      "Epoch 164 / 300: Loss = 0.196 Acc = 1.00\n",
      "Epoch 165 / 300: Loss = 0.193 Acc = 1.00\n",
      "Epoch 166 / 300: Loss = 0.191 Acc = 1.00\n",
      "Epoch 167 / 300: Loss = 0.188 Acc = 1.00\n",
      "Epoch 168 / 300: Loss = 0.186 Acc = 1.00\n",
      "Epoch 169 / 300: Loss = 0.183 Acc = 1.00\n",
      "Epoch 170 / 300: Loss = 0.181 Acc = 1.00\n",
      "Epoch 171 / 300: Loss = 0.179 Acc = 1.00\n",
      "Epoch 172 / 300: Loss = 0.176 Acc = 1.00\n",
      "Epoch 173 / 300: Loss = 0.174 Acc = 1.00\n",
      "Epoch 174 / 300: Loss = 0.172 Acc = 1.00\n",
      "Epoch 175 / 300: Loss = 0.170 Acc = 1.00\n",
      "Epoch 176 / 300: Loss = 0.168 Acc = 1.00\n",
      "Epoch 177 / 300: Loss = 0.165 Acc = 1.00\n",
      "Epoch 178 / 300: Loss = 0.163 Acc = 1.00\n",
      "Epoch 179 / 300: Loss = 0.161 Acc = 1.00\n",
      "Epoch 180 / 300: Loss = 0.159 Acc = 1.00\n",
      "Epoch 181 / 300: Loss = 0.157 Acc = 1.00\n",
      "Epoch 182 / 300: Loss = 0.156 Acc = 1.00\n",
      "Epoch 183 / 300: Loss = 0.154 Acc = 1.00\n",
      "Epoch 184 / 300: Loss = 0.152 Acc = 1.00\n",
      "Epoch 185 / 300: Loss = 0.150 Acc = 1.00\n",
      "Epoch 186 / 300: Loss = 0.148 Acc = 1.00\n",
      "Epoch 187 / 300: Loss = 0.147 Acc = 1.00\n",
      "Epoch 188 / 300: Loss = 0.145 Acc = 1.00\n",
      "Epoch 189 / 300: Loss = 0.143 Acc = 1.00\n",
      "Epoch 190 / 300: Loss = 0.141 Acc = 1.00\n",
      "Epoch 191 / 300: Loss = 0.140 Acc = 1.00\n",
      "Epoch 192 / 300: Loss = 0.138 Acc = 1.00\n",
      "Epoch 193 / 300: Loss = 0.137 Acc = 1.00\n",
      "Epoch 194 / 300: Loss = 0.135 Acc = 1.00\n",
      "Epoch 195 / 300: Loss = 0.134 Acc = 1.00\n",
      "Epoch 196 / 300: Loss = 0.132 Acc = 1.00\n",
      "Epoch 197 / 300: Loss = 0.131 Acc = 1.00\n",
      "Epoch 198 / 300: Loss = 0.129 Acc = 1.00\n",
      "Epoch 199 / 300: Loss = 0.128 Acc = 1.00\n",
      "Epoch 200 / 300: Loss = 0.126 Acc = 1.00\n",
      "Epoch 201 / 300: Loss = 0.125 Acc = 1.00\n",
      "Epoch 202 / 300: Loss = 0.124 Acc = 1.00\n",
      "Epoch 203 / 300: Loss = 0.122 Acc = 1.00\n",
      "Epoch 204 / 300: Loss = 0.121 Acc = 1.00\n",
      "Epoch 205 / 300: Loss = 0.120 Acc = 1.00\n",
      "Epoch 206 / 300: Loss = 0.119 Acc = 1.00\n",
      "Epoch 207 / 300: Loss = 0.117 Acc = 1.00\n",
      "Epoch 208 / 300: Loss = 0.116 Acc = 1.00\n",
      "Epoch 209 / 300: Loss = 0.115 Acc = 1.00\n",
      "Epoch 210 / 300: Loss = 0.114 Acc = 1.00\n",
      "Epoch 211 / 300: Loss = 0.113 Acc = 1.00\n",
      "Epoch 212 / 300: Loss = 0.112 Acc = 1.00\n",
      "Epoch 213 / 300: Loss = 0.110 Acc = 1.00\n",
      "Epoch 214 / 300: Loss = 0.109 Acc = 1.00\n",
      "Epoch 215 / 300: Loss = 0.108 Acc = 1.00\n",
      "Epoch 216 / 300: Loss = 0.107 Acc = 1.00\n",
      "Epoch 217 / 300: Loss = 0.106 Acc = 1.00\n",
      "Epoch 218 / 300: Loss = 0.105 Acc = 1.00\n",
      "Epoch 219 / 300: Loss = 0.104 Acc = 1.00\n",
      "Epoch 220 / 300: Loss = 0.103 Acc = 1.00\n",
      "Epoch 221 / 300: Loss = 0.102 Acc = 1.00\n",
      "Epoch 222 / 300: Loss = 0.101 Acc = 1.00\n",
      "Epoch 223 / 300: Loss = 0.100 Acc = 1.00\n",
      "Epoch 224 / 300: Loss = 0.099 Acc = 1.00\n",
      "Epoch 225 / 300: Loss = 0.098 Acc = 1.00\n",
      "Epoch 226 / 300: Loss = 0.098 Acc = 1.00\n",
      "Epoch 227 / 300: Loss = 0.097 Acc = 1.00\n",
      "Epoch 228 / 300: Loss = 0.096 Acc = 1.00\n",
      "Epoch 229 / 300: Loss = 0.095 Acc = 1.00\n",
      "Epoch 230 / 300: Loss = 0.094 Acc = 1.00\n",
      "Epoch 231 / 300: Loss = 0.093 Acc = 1.00\n",
      "Epoch 232 / 300: Loss = 0.092 Acc = 1.00\n",
      "Epoch 233 / 300: Loss = 0.092 Acc = 1.00\n",
      "Epoch 234 / 300: Loss = 0.091 Acc = 1.00\n",
      "Epoch 235 / 300: Loss = 0.090 Acc = 1.00\n",
      "Epoch 236 / 300: Loss = 0.089 Acc = 1.00\n",
      "Epoch 237 / 300: Loss = 0.089 Acc = 1.00\n",
      "Epoch 238 / 300: Loss = 0.088 Acc = 1.00\n",
      "Epoch 239 / 300: Loss = 0.087 Acc = 1.00\n",
      "Epoch 240 / 300: Loss = 0.086 Acc = 1.00\n",
      "Epoch 241 / 300: Loss = 0.086 Acc = 1.00\n",
      "Epoch 242 / 300: Loss = 0.085 Acc = 1.00\n",
      "Epoch 243 / 300: Loss = 0.084 Acc = 1.00\n",
      "Epoch 244 / 300: Loss = 0.083 Acc = 1.00\n",
      "Epoch 245 / 300: Loss = 0.083 Acc = 1.00\n",
      "Epoch 246 / 300: Loss = 0.082 Acc = 1.00\n",
      "Epoch 247 / 300: Loss = 0.081 Acc = 1.00\n",
      "Epoch 248 / 300: Loss = 0.081 Acc = 1.00\n",
      "Epoch 249 / 300: Loss = 0.080 Acc = 1.00\n",
      "Epoch 250 / 300: Loss = 0.080 Acc = 1.00\n",
      "Epoch 251 / 300: Loss = 0.079 Acc = 1.00\n",
      "Epoch 252 / 300: Loss = 0.078 Acc = 1.00\n",
      "Epoch 253 / 300: Loss = 0.078 Acc = 1.00\n",
      "Epoch 254 / 300: Loss = 0.077 Acc = 1.00\n",
      "Epoch 255 / 300: Loss = 0.077 Acc = 1.00\n",
      "Epoch 256 / 300: Loss = 0.076 Acc = 1.00\n",
      "Epoch 257 / 300: Loss = 0.075 Acc = 1.00\n",
      "Epoch 258 / 300: Loss = 0.075 Acc = 1.00\n",
      "Epoch 259 / 300: Loss = 0.074 Acc = 1.00\n",
      "Epoch 260 / 300: Loss = 0.074 Acc = 1.00\n",
      "Epoch 261 / 300: Loss = 0.073 Acc = 1.00\n",
      "Epoch 262 / 300: Loss = 0.073 Acc = 1.00\n",
      "Epoch 263 / 300: Loss = 0.072 Acc = 1.00\n",
      "Epoch 264 / 300: Loss = 0.072 Acc = 1.00\n",
      "Epoch 265 / 300: Loss = 0.071 Acc = 1.00\n",
      "Epoch 266 / 300: Loss = 0.071 Acc = 1.00\n",
      "Epoch 267 / 300: Loss = 0.070 Acc = 1.00\n",
      "Epoch 268 / 300: Loss = 0.070 Acc = 1.00\n",
      "Epoch 269 / 300: Loss = 0.069 Acc = 1.00\n",
      "Epoch 270 / 300: Loss = 0.069 Acc = 1.00\n",
      "Epoch 271 / 300: Loss = 0.068 Acc = 1.00\n",
      "Epoch 272 / 300: Loss = 0.068 Acc = 1.00\n",
      "Epoch 273 / 300: Loss = 0.067 Acc = 1.00\n",
      "Epoch 274 / 300: Loss = 0.067 Acc = 1.00\n",
      "Epoch 275 / 300: Loss = 0.066 Acc = 1.00\n",
      "Epoch 276 / 300: Loss = 0.066 Acc = 1.00\n",
      "Epoch 277 / 300: Loss = 0.065 Acc = 1.00\n",
      "Epoch 278 / 300: Loss = 0.065 Acc = 1.00\n",
      "Epoch 279 / 300: Loss = 0.064 Acc = 1.00\n",
      "Epoch 280 / 300: Loss = 0.064 Acc = 1.00\n",
      "Epoch 281 / 300: Loss = 0.064 Acc = 1.00\n",
      "Epoch 282 / 300: Loss = 0.063 Acc = 1.00\n",
      "Epoch 283 / 300: Loss = 0.063 Acc = 1.00\n",
      "Epoch 284 / 300: Loss = 0.062 Acc = 1.00\n",
      "Epoch 285 / 300: Loss = 0.062 Acc = 1.00\n",
      "Epoch 286 / 300: Loss = 0.062 Acc = 1.00\n",
      "Epoch 287 / 300: Loss = 0.061 Acc = 1.00\n",
      "Epoch 288 / 300: Loss = 0.061 Acc = 1.00\n",
      "Epoch 289 / 300: Loss = 0.060 Acc = 1.00\n",
      "Epoch 290 / 300: Loss = 0.060 Acc = 1.00\n",
      "Epoch 291 / 300: Loss = 0.060 Acc = 1.00\n",
      "Epoch 292 / 300: Loss = 0.059 Acc = 1.00\n",
      "Epoch 293 / 300: Loss = 0.059 Acc = 1.00\n",
      "Epoch 294 / 300: Loss = 0.058 Acc = 1.00\n",
      "Epoch 295 / 300: Loss = 0.058 Acc = 1.00\n",
      "Epoch 296 / 300: Loss = 0.058 Acc = 1.00\n",
      "Epoch 297 / 300: Loss = 0.057 Acc = 1.00\n",
      "Epoch 298 / 300: Loss = 0.057 Acc = 1.00\n",
      "Epoch 299 / 300: Loss = 0.057 Acc = 1.00\n",
      "Epoch 300 / 300: Loss = 0.056 Acc = 1.00\n"
     ]
    }
   ],
   "source": [
    "history_classical = train(model_classical, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(model):\n",
    "    with torch.no_grad():\n",
    "        input_sentence = training_data[0][0]\n",
    "        labels = training_data[0][1]\n",
    "        inputs = prepare_sequence(input_sentence, word_to_ix)\n",
    "        tag_scores = model(inputs)\n",
    "\n",
    "        tag_ids = torch.argmax(tag_scores, dim=1).numpy()\n",
    "        tag_labels = [ix_to_tag[k] for k in tag_ids]\n",
    "        print(f\"Sentence:  {input_sentence}\")\n",
    "        print(f\"Labels:    {labels}\")\n",
    "        print(f\"Predicted: {tag_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  ['The', 'dog', 'ate', 'the', 'apple']\n",
      "Labels:    ['DET', 'NN', 'V', 'DET', 'NN']\n",
      "Predicted: ['DET', 'NN', 'V', 'DET', 'NN']\n"
     ]
    }
   ],
   "source": [
    "print_result(model_classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger will use Quantum LSTM\n",
      "weight_shapes = (n_qlayers, n_qubits) = (1, 4)\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "\n",
    "model_quantum = LSTMTagger(embedding_dim, \n",
    "                        hidden_dim, \n",
    "                        vocab_size=len(word_to_ix), \n",
    "                        tagset_size=len(tag_to_ix), \n",
    "                        n_qubits=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 300: Loss = 1.071 Acc = 0.44\n",
      "Epoch 2 / 300: Loss = 1.070 Acc = 0.44\n",
      "Epoch 3 / 300: Loss = 1.069 Acc = 0.44\n",
      "Epoch 4 / 300: Loss = 1.068 Acc = 0.44\n",
      "Epoch 5 / 300: Loss = 1.068 Acc = 0.44\n",
      "Epoch 6 / 300: Loss = 1.067 Acc = 0.44\n",
      "Epoch 7 / 300: Loss = 1.066 Acc = 0.44\n",
      "Epoch 8 / 300: Loss = 1.066 Acc = 0.44\n",
      "Epoch 9 / 300: Loss = 1.065 Acc = 0.44\n",
      "Epoch 10 / 300: Loss = 1.065 Acc = 0.44\n",
      "Epoch 11 / 300: Loss = 1.064 Acc = 0.44\n",
      "Epoch 12 / 300: Loss = 1.064 Acc = 0.44\n",
      "Epoch 13 / 300: Loss = 1.064 Acc = 0.44\n",
      "Epoch 14 / 300: Loss = 1.063 Acc = 0.44\n",
      "Epoch 15 / 300: Loss = 1.063 Acc = 0.44\n",
      "Epoch 16 / 300: Loss = 1.062 Acc = 0.44\n",
      "Epoch 17 / 300: Loss = 1.062 Acc = 0.44\n",
      "Epoch 18 / 300: Loss = 1.062 Acc = 0.44\n",
      "Epoch 19 / 300: Loss = 1.062 Acc = 0.44\n",
      "Epoch 20 / 300: Loss = 1.061 Acc = 0.44\n",
      "Epoch 21 / 300: Loss = 1.061 Acc = 0.44\n",
      "Epoch 22 / 300: Loss = 1.061 Acc = 0.44\n",
      "Epoch 23 / 300: Loss = 1.061 Acc = 0.44\n",
      "Epoch 24 / 300: Loss = 1.060 Acc = 0.44\n",
      "Epoch 25 / 300: Loss = 1.060 Acc = 0.44\n",
      "Epoch 26 / 300: Loss = 1.060 Acc = 0.44\n",
      "Epoch 27 / 300: Loss = 1.060 Acc = 0.44\n",
      "Epoch 28 / 300: Loss = 1.059 Acc = 0.44\n",
      "Epoch 29 / 300: Loss = 1.059 Acc = 0.44\n",
      "Epoch 30 / 300: Loss = 1.059 Acc = 0.44\n",
      "Epoch 31 / 300: Loss = 1.059 Acc = 0.44\n",
      "Epoch 32 / 300: Loss = 1.058 Acc = 0.44\n",
      "Epoch 33 / 300: Loss = 1.058 Acc = 0.44\n",
      "Epoch 34 / 300: Loss = 1.058 Acc = 0.44\n",
      "Epoch 35 / 300: Loss = 1.058 Acc = 0.44\n",
      "Epoch 36 / 300: Loss = 1.058 Acc = 0.44\n",
      "Epoch 37 / 300: Loss = 1.057 Acc = 0.44\n",
      "Epoch 38 / 300: Loss = 1.057 Acc = 0.44\n",
      "Epoch 39 / 300: Loss = 1.057 Acc = 0.44\n",
      "Epoch 40 / 300: Loss = 1.057 Acc = 0.44\n",
      "Epoch 41 / 300: Loss = 1.056 Acc = 0.44\n",
      "Epoch 42 / 300: Loss = 1.056 Acc = 0.44\n",
      "Epoch 43 / 300: Loss = 1.056 Acc = 0.44\n",
      "Epoch 44 / 300: Loss = 1.055 Acc = 0.44\n",
      "Epoch 45 / 300: Loss = 1.055 Acc = 0.44\n",
      "Epoch 46 / 300: Loss = 1.055 Acc = 0.44\n",
      "Epoch 47 / 300: Loss = 1.054 Acc = 0.44\n",
      "Epoch 48 / 300: Loss = 1.054 Acc = 0.44\n",
      "Epoch 49 / 300: Loss = 1.054 Acc = 0.44\n",
      "Epoch 50 / 300: Loss = 1.053 Acc = 0.44\n",
      "Epoch 51 / 300: Loss = 1.053 Acc = 0.44\n",
      "Epoch 52 / 300: Loss = 1.053 Acc = 0.44\n",
      "Epoch 53 / 300: Loss = 1.052 Acc = 0.44\n",
      "Epoch 54 / 300: Loss = 1.052 Acc = 0.44\n",
      "Epoch 55 / 300: Loss = 1.051 Acc = 0.44\n",
      "Epoch 56 / 300: Loss = 1.051 Acc = 0.44\n",
      "Epoch 57 / 300: Loss = 1.050 Acc = 0.44\n",
      "Epoch 58 / 300: Loss = 1.050 Acc = 0.44\n",
      "Epoch 59 / 300: Loss = 1.049 Acc = 0.44\n",
      "Epoch 60 / 300: Loss = 1.049 Acc = 0.44\n",
      "Epoch 61 / 300: Loss = 1.048 Acc = 0.44\n",
      "Epoch 62 / 300: Loss = 1.048 Acc = 0.44\n",
      "Epoch 63 / 300: Loss = 1.047 Acc = 0.44\n",
      "Epoch 64 / 300: Loss = 1.046 Acc = 0.44\n",
      "Epoch 65 / 300: Loss = 1.046 Acc = 0.44\n",
      "Epoch 66 / 300: Loss = 1.045 Acc = 0.44\n",
      "Epoch 67 / 300: Loss = 1.044 Acc = 0.44\n",
      "Epoch 68 / 300: Loss = 1.043 Acc = 0.44\n",
      "Epoch 69 / 300: Loss = 1.043 Acc = 0.44\n",
      "Epoch 70 / 300: Loss = 1.042 Acc = 0.44\n",
      "Epoch 71 / 300: Loss = 1.041 Acc = 0.44\n",
      "Epoch 72 / 300: Loss = 1.040 Acc = 0.44\n",
      "Epoch 73 / 300: Loss = 1.039 Acc = 0.44\n",
      "Epoch 74 / 300: Loss = 1.038 Acc = 0.44\n",
      "Epoch 75 / 300: Loss = 1.037 Acc = 0.44\n",
      "Epoch 76 / 300: Loss = 1.036 Acc = 0.44\n",
      "Epoch 77 / 300: Loss = 1.035 Acc = 0.44\n",
      "Epoch 78 / 300: Loss = 1.033 Acc = 0.44\n",
      "Epoch 79 / 300: Loss = 1.032 Acc = 0.44\n",
      "Epoch 80 / 300: Loss = 1.031 Acc = 0.44\n",
      "Epoch 81 / 300: Loss = 1.029 Acc = 0.44\n",
      "Epoch 82 / 300: Loss = 1.028 Acc = 0.44\n",
      "Epoch 83 / 300: Loss = 1.026 Acc = 0.44\n",
      "Epoch 84 / 300: Loss = 1.025 Acc = 0.44\n",
      "Epoch 85 / 300: Loss = 1.023 Acc = 0.44\n",
      "Epoch 86 / 300: Loss = 1.021 Acc = 0.44\n",
      "Epoch 87 / 300: Loss = 1.020 Acc = 0.44\n",
      "Epoch 88 / 300: Loss = 1.018 Acc = 0.44\n",
      "Epoch 89 / 300: Loss = 1.016 Acc = 0.44\n",
      "Epoch 90 / 300: Loss = 1.014 Acc = 0.44\n",
      "Epoch 91 / 300: Loss = 1.012 Acc = 0.44\n",
      "Epoch 92 / 300: Loss = 1.010 Acc = 0.44\n",
      "Epoch 93 / 300: Loss = 1.007 Acc = 0.44\n",
      "Epoch 94 / 300: Loss = 1.005 Acc = 0.44\n",
      "Epoch 95 / 300: Loss = 1.003 Acc = 0.44\n",
      "Epoch 96 / 300: Loss = 1.000 Acc = 0.44\n",
      "Epoch 97 / 300: Loss = 0.997 Acc = 0.44\n",
      "Epoch 98 / 300: Loss = 0.995 Acc = 0.44\n",
      "Epoch 99 / 300: Loss = 0.992 Acc = 0.44\n",
      "Epoch 100 / 300: Loss = 0.989 Acc = 0.44\n",
      "Epoch 101 / 300: Loss = 0.986 Acc = 0.44\n",
      "Epoch 102 / 300: Loss = 0.983 Acc = 0.44\n",
      "Epoch 103 / 300: Loss = 0.980 Acc = 0.44\n",
      "Epoch 104 / 300: Loss = 0.977 Acc = 0.44\n",
      "Epoch 105 / 300: Loss = 0.973 Acc = 0.44\n",
      "Epoch 106 / 300: Loss = 0.970 Acc = 0.44\n",
      "Epoch 107 / 300: Loss = 0.966 Acc = 0.44\n",
      "Epoch 108 / 300: Loss = 0.963 Acc = 0.44\n",
      "Epoch 109 / 300: Loss = 0.959 Acc = 0.44\n",
      "Epoch 110 / 300: Loss = 0.955 Acc = 0.44\n",
      "Epoch 111 / 300: Loss = 0.952 Acc = 0.44\n",
      "Epoch 112 / 300: Loss = 0.948 Acc = 0.44\n",
      "Epoch 113 / 300: Loss = 0.944 Acc = 0.44\n",
      "Epoch 114 / 300: Loss = 0.939 Acc = 0.44\n",
      "Epoch 115 / 300: Loss = 0.935 Acc = 0.44\n",
      "Epoch 116 / 300: Loss = 0.931 Acc = 0.44\n",
      "Epoch 117 / 300: Loss = 0.927 Acc = 0.56\n",
      "Epoch 118 / 300: Loss = 0.922 Acc = 0.56\n",
      "Epoch 119 / 300: Loss = 0.918 Acc = 0.56\n",
      "Epoch 120 / 300: Loss = 0.913 Acc = 0.56\n",
      "Epoch 121 / 300: Loss = 0.909 Acc = 0.56\n",
      "Epoch 122 / 300: Loss = 0.904 Acc = 0.67\n",
      "Epoch 123 / 300: Loss = 0.899 Acc = 0.67\n",
      "Epoch 124 / 300: Loss = 0.894 Acc = 0.67\n",
      "Epoch 125 / 300: Loss = 0.889 Acc = 0.67\n",
      "Epoch 126 / 300: Loss = 0.885 Acc = 0.67\n",
      "Epoch 127 / 300: Loss = 0.880 Acc = 0.67\n",
      "Epoch 128 / 300: Loss = 0.875 Acc = 0.67\n",
      "Epoch 129 / 300: Loss = 0.869 Acc = 0.67\n",
      "Epoch 130 / 300: Loss = 0.864 Acc = 0.67\n",
      "Epoch 131 / 300: Loss = 0.859 Acc = 0.67\n",
      "Epoch 132 / 300: Loss = 0.854 Acc = 0.67\n",
      "Epoch 133 / 300: Loss = 0.849 Acc = 0.67\n",
      "Epoch 134 / 300: Loss = 0.844 Acc = 0.67\n",
      "Epoch 135 / 300: Loss = 0.838 Acc = 0.67\n",
      "Epoch 136 / 300: Loss = 0.833 Acc = 0.67\n",
      "Epoch 137 / 300: Loss = 0.828 Acc = 0.67\n",
      "Epoch 138 / 300: Loss = 0.823 Acc = 0.67\n",
      "Epoch 139 / 300: Loss = 0.817 Acc = 0.67\n",
      "Epoch 140 / 300: Loss = 0.812 Acc = 0.67\n",
      "Epoch 141 / 300: Loss = 0.807 Acc = 0.67\n",
      "Epoch 142 / 300: Loss = 0.802 Acc = 0.67\n",
      "Epoch 143 / 300: Loss = 0.797 Acc = 0.67\n",
      "Epoch 144 / 300: Loss = 0.791 Acc = 0.67\n",
      "Epoch 145 / 300: Loss = 0.786 Acc = 0.67\n",
      "Epoch 146 / 300: Loss = 0.781 Acc = 0.67\n",
      "Epoch 147 / 300: Loss = 0.776 Acc = 0.67\n",
      "Epoch 148 / 300: Loss = 0.771 Acc = 0.67\n",
      "Epoch 149 / 300: Loss = 0.766 Acc = 0.67\n",
      "Epoch 150 / 300: Loss = 0.761 Acc = 0.67\n",
      "Epoch 151 / 300: Loss = 0.756 Acc = 0.67\n",
      "Epoch 152 / 300: Loss = 0.751 Acc = 0.67\n",
      "Epoch 153 / 300: Loss = 0.746 Acc = 0.67\n",
      "Epoch 154 / 300: Loss = 0.741 Acc = 0.67\n",
      "Epoch 155 / 300: Loss = 0.736 Acc = 0.67\n",
      "Epoch 156 / 300: Loss = 0.732 Acc = 0.67\n",
      "Epoch 157 / 300: Loss = 0.727 Acc = 0.67\n",
      "Epoch 158 / 300: Loss = 0.722 Acc = 0.67\n",
      "Epoch 159 / 300: Loss = 0.717 Acc = 0.67\n",
      "Epoch 160 / 300: Loss = 0.713 Acc = 0.67\n",
      "Epoch 161 / 300: Loss = 0.708 Acc = 0.67\n",
      "Epoch 162 / 300: Loss = 0.703 Acc = 0.67\n",
      "Epoch 163 / 300: Loss = 0.699 Acc = 0.67\n",
      "Epoch 164 / 300: Loss = 0.694 Acc = 0.67\n",
      "Epoch 165 / 300: Loss = 0.690 Acc = 0.67\n",
      "Epoch 166 / 300: Loss = 0.685 Acc = 0.67\n",
      "Epoch 167 / 300: Loss = 0.681 Acc = 0.67\n",
      "Epoch 168 / 300: Loss = 0.676 Acc = 0.67\n",
      "Epoch 169 / 300: Loss = 0.672 Acc = 0.67\n",
      "Epoch 170 / 300: Loss = 0.667 Acc = 0.67\n",
      "Epoch 171 / 300: Loss = 0.663 Acc = 0.67\n",
      "Epoch 172 / 300: Loss = 0.658 Acc = 0.67\n",
      "Epoch 173 / 300: Loss = 0.654 Acc = 0.67\n",
      "Epoch 174 / 300: Loss = 0.649 Acc = 0.67\n",
      "Epoch 175 / 300: Loss = 0.645 Acc = 0.67\n",
      "Epoch 176 / 300: Loss = 0.640 Acc = 0.67\n",
      "Epoch 177 / 300: Loss = 0.636 Acc = 0.67\n",
      "Epoch 178 / 300: Loss = 0.631 Acc = 0.67\n",
      "Epoch 179 / 300: Loss = 0.627 Acc = 0.67\n",
      "Epoch 180 / 300: Loss = 0.622 Acc = 0.78\n",
      "Epoch 181 / 300: Loss = 0.617 Acc = 0.78\n",
      "Epoch 182 / 300: Loss = 0.613 Acc = 0.78\n",
      "Epoch 183 / 300: Loss = 0.608 Acc = 0.78\n",
      "Epoch 184 / 300: Loss = 0.603 Acc = 0.78\n",
      "Epoch 185 / 300: Loss = 0.598 Acc = 0.78\n",
      "Epoch 186 / 300: Loss = 0.594 Acc = 0.78\n",
      "Epoch 187 / 300: Loss = 0.589 Acc = 0.78\n",
      "Epoch 188 / 300: Loss = 0.583 Acc = 0.78\n",
      "Epoch 189 / 300: Loss = 0.578 Acc = 0.78\n",
      "Epoch 190 / 300: Loss = 0.573 Acc = 0.78\n",
      "Epoch 191 / 300: Loss = 0.568 Acc = 0.78\n",
      "Epoch 192 / 300: Loss = 0.562 Acc = 0.78\n",
      "Epoch 193 / 300: Loss = 0.557 Acc = 0.78\n",
      "Epoch 194 / 300: Loss = 0.551 Acc = 0.78\n",
      "Epoch 195 / 300: Loss = 0.545 Acc = 0.78\n",
      "Epoch 196 / 300: Loss = 0.539 Acc = 0.78\n",
      "Epoch 197 / 300: Loss = 0.533 Acc = 0.78\n",
      "Epoch 198 / 300: Loss = 0.527 Acc = 0.78\n",
      "Epoch 199 / 300: Loss = 0.521 Acc = 0.78\n",
      "Epoch 200 / 300: Loss = 0.515 Acc = 0.78\n",
      "Epoch 201 / 300: Loss = 0.509 Acc = 0.78\n",
      "Epoch 202 / 300: Loss = 0.503 Acc = 0.78\n",
      "Epoch 203 / 300: Loss = 0.497 Acc = 0.78\n",
      "Epoch 204 / 300: Loss = 0.491 Acc = 0.78\n",
      "Epoch 205 / 300: Loss = 0.485 Acc = 0.89\n",
      "Epoch 206 / 300: Loss = 0.479 Acc = 1.00\n",
      "Epoch 207 / 300: Loss = 0.473 Acc = 1.00\n",
      "Epoch 208 / 300: Loss = 0.467 Acc = 1.00\n",
      "Epoch 209 / 300: Loss = 0.461 Acc = 1.00\n",
      "Epoch 210 / 300: Loss = 0.455 Acc = 1.00\n",
      "Epoch 211 / 300: Loss = 0.449 Acc = 1.00\n",
      "Epoch 212 / 300: Loss = 0.443 Acc = 1.00\n",
      "Epoch 213 / 300: Loss = 0.437 Acc = 1.00\n",
      "Epoch 214 / 300: Loss = 0.431 Acc = 1.00\n",
      "Epoch 215 / 300: Loss = 0.425 Acc = 1.00\n",
      "Epoch 216 / 300: Loss = 0.419 Acc = 1.00\n",
      "Epoch 217 / 300: Loss = 0.414 Acc = 1.00\n",
      "Epoch 218 / 300: Loss = 0.408 Acc = 1.00\n",
      "Epoch 219 / 300: Loss = 0.402 Acc = 1.00\n",
      "Epoch 220 / 300: Loss = 0.396 Acc = 1.00\n",
      "Epoch 221 / 300: Loss = 0.390 Acc = 1.00\n",
      "Epoch 222 / 300: Loss = 0.385 Acc = 1.00\n",
      "Epoch 223 / 300: Loss = 0.379 Acc = 1.00\n",
      "Epoch 224 / 300: Loss = 0.373 Acc = 1.00\n",
      "Epoch 225 / 300: Loss = 0.368 Acc = 1.00\n",
      "Epoch 226 / 300: Loss = 0.362 Acc = 1.00\n",
      "Epoch 227 / 300: Loss = 0.357 Acc = 1.00\n",
      "Epoch 228 / 300: Loss = 0.351 Acc = 1.00\n",
      "Epoch 229 / 300: Loss = 0.346 Acc = 1.00\n",
      "Epoch 230 / 300: Loss = 0.340 Acc = 1.00\n",
      "Epoch 231 / 300: Loss = 0.335 Acc = 1.00\n",
      "Epoch 232 / 300: Loss = 0.330 Acc = 1.00\n",
      "Epoch 233 / 300: Loss = 0.324 Acc = 1.00\n",
      "Epoch 234 / 300: Loss = 0.319 Acc = 1.00\n",
      "Epoch 235 / 300: Loss = 0.314 Acc = 1.00\n",
      "Epoch 236 / 300: Loss = 0.309 Acc = 1.00\n",
      "Epoch 237 / 300: Loss = 0.304 Acc = 1.00\n",
      "Epoch 238 / 300: Loss = 0.299 Acc = 1.00\n",
      "Epoch 239 / 300: Loss = 0.294 Acc = 1.00\n",
      "Epoch 240 / 300: Loss = 0.289 Acc = 1.00\n",
      "Epoch 241 / 300: Loss = 0.285 Acc = 1.00\n",
      "Epoch 242 / 300: Loss = 0.280 Acc = 1.00\n",
      "Epoch 243 / 300: Loss = 0.275 Acc = 1.00\n",
      "Epoch 244 / 300: Loss = 0.271 Acc = 1.00\n",
      "Epoch 245 / 300: Loss = 0.266 Acc = 1.00\n",
      "Epoch 246 / 300: Loss = 0.262 Acc = 1.00\n",
      "Epoch 247 / 300: Loss = 0.258 Acc = 1.00\n",
      "Epoch 248 / 300: Loss = 0.254 Acc = 1.00\n",
      "Epoch 249 / 300: Loss = 0.249 Acc = 1.00\n",
      "Epoch 250 / 300: Loss = 0.245 Acc = 1.00\n",
      "Epoch 251 / 300: Loss = 0.241 Acc = 1.00\n",
      "Epoch 252 / 300: Loss = 0.237 Acc = 1.00\n",
      "Epoch 253 / 300: Loss = 0.233 Acc = 1.00\n",
      "Epoch 254 / 300: Loss = 0.230 Acc = 1.00\n",
      "Epoch 255 / 300: Loss = 0.226 Acc = 1.00\n",
      "Epoch 256 / 300: Loss = 0.222 Acc = 1.00\n",
      "Epoch 257 / 300: Loss = 0.219 Acc = 1.00\n",
      "Epoch 258 / 300: Loss = 0.215 Acc = 1.00\n",
      "Epoch 259 / 300: Loss = 0.212 Acc = 1.00\n",
      "Epoch 260 / 300: Loss = 0.208 Acc = 1.00\n",
      "Epoch 261 / 300: Loss = 0.205 Acc = 1.00\n",
      "Epoch 262 / 300: Loss = 0.202 Acc = 1.00\n",
      "Epoch 263 / 300: Loss = 0.199 Acc = 1.00\n",
      "Epoch 264 / 300: Loss = 0.196 Acc = 1.00\n",
      "Epoch 265 / 300: Loss = 0.193 Acc = 1.00\n",
      "Epoch 266 / 300: Loss = 0.190 Acc = 1.00\n",
      "Epoch 267 / 300: Loss = 0.187 Acc = 1.00\n",
      "Epoch 268 / 300: Loss = 0.184 Acc = 1.00\n",
      "Epoch 269 / 300: Loss = 0.181 Acc = 1.00\n",
      "Epoch 270 / 300: Loss = 0.179 Acc = 1.00\n",
      "Epoch 271 / 300: Loss = 0.176 Acc = 1.00\n",
      "Epoch 272 / 300: Loss = 0.174 Acc = 1.00\n",
      "Epoch 273 / 300: Loss = 0.171 Acc = 1.00\n",
      "Epoch 274 / 300: Loss = 0.169 Acc = 1.00\n",
      "Epoch 275 / 300: Loss = 0.166 Acc = 1.00\n",
      "Epoch 276 / 300: Loss = 0.164 Acc = 1.00\n",
      "Epoch 277 / 300: Loss = 0.162 Acc = 1.00\n",
      "Epoch 278 / 300: Loss = 0.160 Acc = 1.00\n",
      "Epoch 279 / 300: Loss = 0.157 Acc = 1.00\n",
      "Epoch 280 / 300: Loss = 0.155 Acc = 1.00\n",
      "Epoch 281 / 300: Loss = 0.153 Acc = 1.00\n",
      "Epoch 282 / 300: Loss = 0.151 Acc = 1.00\n",
      "Epoch 283 / 300: Loss = 0.149 Acc = 1.00\n",
      "Epoch 284 / 300: Loss = 0.147 Acc = 1.00\n",
      "Epoch 285 / 300: Loss = 0.145 Acc = 1.00\n",
      "Epoch 286 / 300: Loss = 0.143 Acc = 1.00\n",
      "Epoch 287 / 300: Loss = 0.142 Acc = 1.00\n",
      "Epoch 288 / 300: Loss = 0.140 Acc = 1.00\n",
      "Epoch 289 / 300: Loss = 0.138 Acc = 1.00\n",
      "Epoch 290 / 300: Loss = 0.136 Acc = 1.00\n",
      "Epoch 291 / 300: Loss = 0.135 Acc = 1.00\n",
      "Epoch 292 / 300: Loss = 0.133 Acc = 1.00\n",
      "Epoch 293 / 300: Loss = 0.131 Acc = 1.00\n",
      "Epoch 294 / 300: Loss = 0.130 Acc = 1.00\n",
      "Epoch 295 / 300: Loss = 0.128 Acc = 1.00\n",
      "Epoch 296 / 300: Loss = 0.127 Acc = 1.00\n",
      "Epoch 297 / 300: Loss = 0.125 Acc = 1.00\n",
      "Epoch 298 / 300: Loss = 0.124 Acc = 1.00\n",
      "Epoch 299 / 300: Loss = 0.122 Acc = 1.00\n",
      "Epoch 300 / 300: Loss = 0.121 Acc = 1.00\n"
     ]
    }
   ],
   "source": [
    "history_quantum = train(model_quantum, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  ['The', 'dog', 'ate', 'the', 'apple']\n",
      "Labels:    ['DET', 'NN', 'V', 'DET', 'NN']\n",
      "Predicted: ['DET', 'NN', 'V', 'DET', 'NN']\n"
     ]
    }
   ],
   "source": [
    "print_result(model_quantum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_history(history_classical, history_quantum):\n",
    "    loss_c = history_classical['loss']\n",
    "    acc_c = history_classical['acc']\n",
    "    loss_q = history_quantum['loss']\n",
    "    acc_q = history_quantum['acc']\n",
    "    n_epochs = max([len(loss_c), len(loss_q)])\n",
    "    x_epochs = [i for i in range(n_epochs)]\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.plot(loss_c, label=\"Classical LSTM loss\", color='orange', linestyle='dashed')\n",
    "    ax1.plot(loss_q, label=\"Quantum LSTM loss\", color='red', linestyle='solid')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.plot(acc_c, label=\"Classical LSTM accuracy\", color='steelblue', linestyle='dashed')\n",
    "    ax2.plot(acc_q, label=\"Quantum LSTM accuracy\", color='blue', linestyle='solid')\n",
    "\n",
    "    plt.title(\"Part-of-Speech Tagger Training\")\n",
    "    plt.ylim(0., 1.1)\n",
    "    #plt.legend(loc=\"upper right\")\n",
    "    fig.legend(loc=\"upper right\", bbox_to_anchor=(1,0.8), bbox_transform=ax1.transAxes)\n",
    "\n",
    "    plt.savefig(\"pos_training.pdf\")\n",
    "    plt.savefig(\"pos_training.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_classical, history_quantum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function decreases as a function of the training epoch, and after 300 epochs both networks are able to tag correctly the first sentence. Due to the complexity of the simulation of the quantum circuit, it took approximatively 15 minutes to finish the training, to be compared to a mere 8 seconds for the classical case. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d4e8c657857f8450e5ea1dd61e524b6df2be80a0331bd50c0d2e4e3fe46c7a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('QLSTM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
