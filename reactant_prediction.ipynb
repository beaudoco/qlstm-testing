{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quantum-Enhanced LSTM Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One field that so far has been poorly explored in Quantum Machine Learning is Natural Language Processing (NLP), the sub-field of Artificial Intelligence that gives computers the ability to read, write and to some extent comprehend written text. \n",
    "\n",
    "As documents are usually presented as sequences of words, historically one of the most successful techniques to manipulate this kind of data has been the Recurrent Neural Network architecture, and in particular a variant called Long Short-Term Memory (LSTM). LSTMs allowed machines to perform translations, classification and intent detection with state-of-the-art accuracy until the advent of Transformer networks. Still, it’s interesting at least from an educational point of view to dig into LSTMs to see what good quantum computing may bring to the field. For a more thorough discussion, please refer to “Quantum Long Short-Term Memory” by Chen, Yoo and Fang (arXiv:2009.01783) and “Recurrent Quantum Neural Networks” by J. Bausch (arXiv:2006.14619)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cpb5867\\Anaconda3\\envs\\QLSTM\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from qlstm_pennylane import QLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the possible tags: determinant, noun, verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_to_ix = {\"<RX_1>\": 0, \"<RX_2>\": 1, \"<RX_3>\": 2, \"<RX_4>\": 3, \"<RX_5>\": 4, \"<RX_6>\": 5, \"<RX_7>\": 6, \"<RX_8>\": 7, \"<RX_9>\": 8, \"<RX_10>\": 9 }  # Assign each tag with a unique index\n",
    "# ix_to_tag = {i:k for k,i in tag_to_ix.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below tokenizes the sentence and matches the label to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    # idxs = [to_ix[w] for w in seq]\n",
    "    idxs = [to_ix[seq]]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_reaction_type = '<RX_1>'\n",
    "reactions = []\n",
    "smiles = open('USPTO-50K/src-train.txt', 'r')\n",
    "content = smiles.read()\n",
    "smile_strings = content.split('\\n')\n",
    "smile_strings.remove('')\n",
    "\n",
    "reactants = []\n",
    "smiles2 = open('USPTO-50K/tgt-train.txt', 'r')\n",
    "content2 = smiles2.read()\n",
    "smile_strings2 = content2.split('\\n')\n",
    "smile_strings2.remove('')\n",
    "\n",
    "for idx in range(len(smile_strings)):\n",
    "    reaction_type = smile_strings[idx].replace(\" \", \"\").split('>',1)[0] + '>'\n",
    "    if reaction_type != None and goal_reaction_type in reaction_type:\n",
    "        reactions.append(smile_strings[idx].replace(\" \", \"\").split('>',1)[1])\n",
    "        reactants.append(smile_strings2[idx].replace(\" \", \"\"))\n",
    "    smile_strings[idx] = smile_strings[idx].replace(\" \", \"\").split('>',1)[1]\n",
    "    \n",
    "smiles.close()\n",
    "smiles2.close()\n",
    "\n",
    "# print(len(reactions))\n",
    "\n",
    "tag_to_ix = {}\n",
    "for reactant in reactants:\n",
    "    if reactant not in tag_to_ix:  # word has not been assigned an index yet\n",
    "        tag_to_ix[reactant] = len(tag_to_ix)  # Assign each word with a unique index\n",
    "\n",
    "\n",
    "# tag_to_ix = {\"<RX_1>\": 0, \"<RX_2>\": 1, \"<RX_3>\": 2, \"<RX_4>\": 3, \"<RX_5>\": 4, \"<RX_6>\": 5, \"<RX_7>\": 6, \"<RX_8>\": 7, \"<RX_9>\": 8, \"<RX_10>\": 9 }  # Assign each tag with a unique index\n",
    "ix_to_tag = {i:k for k,i in tag_to_ix.items()}\n",
    "\n",
    "# print(tmp_arr)\n",
    "# print(tag_to_ix[-3:])\n",
    "# print(ix_to_tag[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can prepare the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('COc1ccc(N(C)c2nc(N(C)C)nc3ccc([N+](=O)[O-])cc23)cc1', 'CNC.COc1ccc(N(C)c2nc(Cl)nc3ccc([N+](=O)[O-])cc23)cc1'), ('COc1cc2c(cc1OC)[C@@H](CN(C)CCCNCC(OC)OC)C2', 'COC(C=O)OC.COc1cc2c(cc1OC)[C@@H](CN(C)CCCN)C2'), ('CCCn1cc(CC)nc1-c1cnc(Nc2ccc(Cl)cc2)c(Cl)c1', 'CCCI.CCc1c[nH]c(-c2cnc(Nc3ccc(Cl)cc3)c(Cl)c2)n1'), ('COC(=O)c1ncc(NS(=O)(=O)c2ccncc2)cc1F', 'COC(=O)c1ncc(Br)cc1F.NS(=O)(=O)c1ccncc1'), ('Cc1nc2ccccc2n1-c1nc(N2CCOCC2)c2nc(CN3CCC(C#N)CC3)n(C)c2n1', 'Cc1nc2ccccc2n1-c1nc(N2CCOCC2)c2nc(CBr)n(C)c2n1.N#CC1CCNCC1')]\n"
     ]
    }
   ],
   "source": [
    "# training_data = [\n",
    "#     # Tags are: DET - determiner; NN - noun; V - verb\n",
    "#     # For example, the word \"The\" is a determiner\n",
    "#     (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "#     (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "# ]\n",
    "training_data = list(zip(reactions, reactants))\n",
    "\n",
    "training_data = training_data[-5:]\n",
    "print(training_data)\n",
    "\n",
    "word_to_ix = {}\n",
    "\n",
    "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
    "for sent, tags in training_data:\n",
    "    if sent not in word_to_ix:  # word has not been assigned an index yet\n",
    "        word_to_ix[sent] = len(word_to_ix)  # Assign each word with a unique index\n",
    "\n",
    "# print(f\"Vocabulary: {word_to_ix}\")\n",
    "# print(f\"Entities: {ix_to_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to pass the two sequences through the LSTM, which will output the hidden array of vectors [h_0, h_1, h_2, h_3, h_4], one for each word. A dense layer “head” is attached to the LSTM’s outputs to calculate the probability that each word may be a determinant, noun or verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, n_qubits=0):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        if n_qubits > 0:\n",
    "            print(\"Tagger will use Quantum LSTM\")\n",
    "            self.lstm = QLSTM(embedding_dim, hidden_dim, n_qubits=n_qubits)\n",
    "        else:\n",
    "            print(\"Tagger will use Classical LSTM\")\n",
    "            self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # print(sentence)\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        # lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        lstm_out, _ = self.lstm(embeds.view(1, 1, -1))\n",
    "        # tag_logits = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_logits = self.hidden2tag(lstm_out.view(1, -1))\n",
    "        tag_scores = F.log_softmax(tag_logits, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 8\n",
    "hidden_dim = 6\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger will use Classical LSTM\n"
     ]
    }
   ],
   "source": [
    "model_classical = LSTMTagger(embedding_dim, \n",
    "                        hidden_dim, \n",
    "                        vocab_size=len(word_to_ix), \n",
    "                        tagset_size=len(tag_to_ix), \n",
    "                        n_qubits=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example from the PyTorch website, we train the two networks (classical and quantum LSTM) for 300 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epochs):\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    history = {\n",
    "        'loss': [],\n",
    "        'acc': []\n",
    "    }\n",
    "    for epoch in range(n_epochs):\n",
    "        losses = []\n",
    "        preds = []\n",
    "        targets = []\n",
    "        for sentence, tags in training_data:\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "            labels = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            tag_scores = model(sentence_in)\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            # print(\"Scores\")\n",
    "            # print(tag_scores)\n",
    "            # print(\"Labels\")\n",
    "            # print(labels)\n",
    "            \n",
    "            loss = loss_function(tag_scores, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(float(loss))\n",
    "            \n",
    "            probs = torch.softmax(tag_scores, dim=-1)\n",
    "            preds.append(probs.argmax(dim=-1))\n",
    "            targets.append(labels)\n",
    "\n",
    "        avg_loss = np.mean(losses)\n",
    "        history['loss'].append(avg_loss)\n",
    "        \n",
    "        preds = torch.cat(preds)\n",
    "        targets = torch.cat(targets)\n",
    "        corrects = (preds == targets)\n",
    "        accuracy = corrects.sum().float() / float(targets.size(0) )\n",
    "        history['acc'].append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} / {n_epochs}: Loss = {avg_loss:.3f} Acc = {accuracy:.2f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 300: Loss = 9.344 Acc = 0.00\n",
      "Epoch 2 / 300: Loss = 9.216 Acc = 0.00\n",
      "Epoch 3 / 300: Loss = 9.089 Acc = 0.40\n",
      "Epoch 4 / 300: Loss = 8.960 Acc = 0.40\n",
      "Epoch 5 / 300: Loss = 8.831 Acc = 0.40\n",
      "Epoch 6 / 300: Loss = 8.700 Acc = 0.40\n",
      "Epoch 7 / 300: Loss = 8.567 Acc = 0.40\n",
      "Epoch 8 / 300: Loss = 8.431 Acc = 0.40\n",
      "Epoch 9 / 300: Loss = 8.291 Acc = 0.40\n",
      "Epoch 10 / 300: Loss = 8.147 Acc = 0.40\n",
      "Epoch 11 / 300: Loss = 7.999 Acc = 0.40\n",
      "Epoch 12 / 300: Loss = 7.846 Acc = 0.40\n",
      "Epoch 13 / 300: Loss = 7.687 Acc = 0.60\n",
      "Epoch 14 / 300: Loss = 7.523 Acc = 0.60\n",
      "Epoch 15 / 300: Loss = 7.352 Acc = 0.80\n",
      "Epoch 16 / 300: Loss = 7.174 Acc = 0.80\n",
      "Epoch 17 / 300: Loss = 6.990 Acc = 0.80\n",
      "Epoch 18 / 300: Loss = 6.798 Acc = 0.80\n",
      "Epoch 19 / 300: Loss = 6.598 Acc = 0.80\n",
      "Epoch 20 / 300: Loss = 6.389 Acc = 0.80\n",
      "Epoch 21 / 300: Loss = 6.173 Acc = 0.80\n",
      "Epoch 22 / 300: Loss = 5.947 Acc = 0.80\n",
      "Epoch 23 / 300: Loss = 5.713 Acc = 0.80\n",
      "Epoch 24 / 300: Loss = 5.470 Acc = 0.80\n",
      "Epoch 25 / 300: Loss = 5.218 Acc = 0.80\n",
      "Epoch 26 / 300: Loss = 4.957 Acc = 0.80\n",
      "Epoch 27 / 300: Loss = 4.688 Acc = 1.00\n",
      "Epoch 28 / 300: Loss = 4.411 Acc = 1.00\n",
      "Epoch 29 / 300: Loss = 4.127 Acc = 1.00\n",
      "Epoch 30 / 300: Loss = 3.839 Acc = 1.00\n",
      "Epoch 31 / 300: Loss = 3.547 Acc = 1.00\n",
      "Epoch 32 / 300: Loss = 3.256 Acc = 1.00\n",
      "Epoch 33 / 300: Loss = 2.966 Acc = 1.00\n",
      "Epoch 34 / 300: Loss = 2.683 Acc = 1.00\n",
      "Epoch 35 / 300: Loss = 2.408 Acc = 1.00\n",
      "Epoch 36 / 300: Loss = 2.148 Acc = 1.00\n",
      "Epoch 37 / 300: Loss = 1.903 Acc = 1.00\n",
      "Epoch 38 / 300: Loss = 1.679 Acc = 1.00\n",
      "Epoch 39 / 300: Loss = 1.475 Acc = 1.00\n",
      "Epoch 40 / 300: Loss = 1.293 Acc = 1.00\n",
      "Epoch 41 / 300: Loss = 1.132 Acc = 1.00\n",
      "Epoch 42 / 300: Loss = 0.993 Acc = 1.00\n",
      "Epoch 43 / 300: Loss = 0.872 Acc = 1.00\n",
      "Epoch 44 / 300: Loss = 0.768 Acc = 1.00\n",
      "Epoch 45 / 300: Loss = 0.679 Acc = 1.00\n",
      "Epoch 46 / 300: Loss = 0.604 Acc = 1.00\n",
      "Epoch 47 / 300: Loss = 0.539 Acc = 1.00\n",
      "Epoch 48 / 300: Loss = 0.484 Acc = 1.00\n",
      "Epoch 49 / 300: Loss = 0.437 Acc = 1.00\n",
      "Epoch 50 / 300: Loss = 0.396 Acc = 1.00\n",
      "Epoch 51 / 300: Loss = 0.362 Acc = 1.00\n",
      "Epoch 52 / 300: Loss = 0.332 Acc = 1.00\n",
      "Epoch 53 / 300: Loss = 0.306 Acc = 1.00\n",
      "Epoch 54 / 300: Loss = 0.284 Acc = 1.00\n",
      "Epoch 55 / 300: Loss = 0.264 Acc = 1.00\n",
      "Epoch 56 / 300: Loss = 0.246 Acc = 1.00\n",
      "Epoch 57 / 300: Loss = 0.231 Acc = 1.00\n",
      "Epoch 58 / 300: Loss = 0.217 Acc = 1.00\n",
      "Epoch 59 / 300: Loss = 0.205 Acc = 1.00\n",
      "Epoch 60 / 300: Loss = 0.194 Acc = 1.00\n",
      "Epoch 61 / 300: Loss = 0.184 Acc = 1.00\n",
      "Epoch 62 / 300: Loss = 0.175 Acc = 1.00\n",
      "Epoch 63 / 300: Loss = 0.167 Acc = 1.00\n",
      "Epoch 64 / 300: Loss = 0.159 Acc = 1.00\n",
      "Epoch 65 / 300: Loss = 0.152 Acc = 1.00\n",
      "Epoch 66 / 300: Loss = 0.146 Acc = 1.00\n",
      "Epoch 67 / 300: Loss = 0.140 Acc = 1.00\n",
      "Epoch 68 / 300: Loss = 0.135 Acc = 1.00\n",
      "Epoch 69 / 300: Loss = 0.130 Acc = 1.00\n",
      "Epoch 70 / 300: Loss = 0.125 Acc = 1.00\n",
      "Epoch 71 / 300: Loss = 0.121 Acc = 1.00\n",
      "Epoch 72 / 300: Loss = 0.117 Acc = 1.00\n",
      "Epoch 73 / 300: Loss = 0.113 Acc = 1.00\n",
      "Epoch 74 / 300: Loss = 0.110 Acc = 1.00\n",
      "Epoch 75 / 300: Loss = 0.106 Acc = 1.00\n",
      "Epoch 76 / 300: Loss = 0.103 Acc = 1.00\n",
      "Epoch 77 / 300: Loss = 0.100 Acc = 1.00\n",
      "Epoch 78 / 300: Loss = 0.098 Acc = 1.00\n",
      "Epoch 79 / 300: Loss = 0.095 Acc = 1.00\n",
      "Epoch 80 / 300: Loss = 0.092 Acc = 1.00\n",
      "Epoch 81 / 300: Loss = 0.090 Acc = 1.00\n",
      "Epoch 82 / 300: Loss = 0.088 Acc = 1.00\n",
      "Epoch 83 / 300: Loss = 0.086 Acc = 1.00\n",
      "Epoch 84 / 300: Loss = 0.084 Acc = 1.00\n",
      "Epoch 85 / 300: Loss = 0.082 Acc = 1.00\n",
      "Epoch 86 / 300: Loss = 0.080 Acc = 1.00\n",
      "Epoch 87 / 300: Loss = 0.078 Acc = 1.00\n",
      "Epoch 88 / 300: Loss = 0.076 Acc = 1.00\n",
      "Epoch 89 / 300: Loss = 0.075 Acc = 1.00\n",
      "Epoch 90 / 300: Loss = 0.073 Acc = 1.00\n",
      "Epoch 91 / 300: Loss = 0.072 Acc = 1.00\n",
      "Epoch 92 / 300: Loss = 0.070 Acc = 1.00\n",
      "Epoch 93 / 300: Loss = 0.069 Acc = 1.00\n",
      "Epoch 94 / 300: Loss = 0.068 Acc = 1.00\n",
      "Epoch 95 / 300: Loss = 0.066 Acc = 1.00\n",
      "Epoch 96 / 300: Loss = 0.065 Acc = 1.00\n",
      "Epoch 97 / 300: Loss = 0.064 Acc = 1.00\n",
      "Epoch 98 / 300: Loss = 0.063 Acc = 1.00\n",
      "Epoch 99 / 300: Loss = 0.062 Acc = 1.00\n",
      "Epoch 100 / 300: Loss = 0.061 Acc = 1.00\n",
      "Epoch 101 / 300: Loss = 0.060 Acc = 1.00\n",
      "Epoch 102 / 300: Loss = 0.059 Acc = 1.00\n",
      "Epoch 103 / 300: Loss = 0.058 Acc = 1.00\n",
      "Epoch 104 / 300: Loss = 0.057 Acc = 1.00\n",
      "Epoch 105 / 300: Loss = 0.056 Acc = 1.00\n",
      "Epoch 106 / 300: Loss = 0.055 Acc = 1.00\n",
      "Epoch 107 / 300: Loss = 0.054 Acc = 1.00\n",
      "Epoch 108 / 300: Loss = 0.053 Acc = 1.00\n",
      "Epoch 109 / 300: Loss = 0.053 Acc = 1.00\n",
      "Epoch 110 / 300: Loss = 0.052 Acc = 1.00\n",
      "Epoch 111 / 300: Loss = 0.051 Acc = 1.00\n",
      "Epoch 112 / 300: Loss = 0.050 Acc = 1.00\n",
      "Epoch 113 / 300: Loss = 0.050 Acc = 1.00\n",
      "Epoch 114 / 300: Loss = 0.049 Acc = 1.00\n",
      "Epoch 115 / 300: Loss = 0.048 Acc = 1.00\n",
      "Epoch 116 / 300: Loss = 0.048 Acc = 1.00\n",
      "Epoch 117 / 300: Loss = 0.047 Acc = 1.00\n",
      "Epoch 118 / 300: Loss = 0.046 Acc = 1.00\n",
      "Epoch 119 / 300: Loss = 0.046 Acc = 1.00\n",
      "Epoch 120 / 300: Loss = 0.045 Acc = 1.00\n",
      "Epoch 121 / 300: Loss = 0.045 Acc = 1.00\n",
      "Epoch 122 / 300: Loss = 0.044 Acc = 1.00\n",
      "Epoch 123 / 300: Loss = 0.044 Acc = 1.00\n",
      "Epoch 124 / 300: Loss = 0.043 Acc = 1.00\n",
      "Epoch 125 / 300: Loss = 0.042 Acc = 1.00\n",
      "Epoch 126 / 300: Loss = 0.042 Acc = 1.00\n",
      "Epoch 127 / 300: Loss = 0.041 Acc = 1.00\n",
      "Epoch 128 / 300: Loss = 0.041 Acc = 1.00\n",
      "Epoch 129 / 300: Loss = 0.041 Acc = 1.00\n",
      "Epoch 130 / 300: Loss = 0.040 Acc = 1.00\n",
      "Epoch 131 / 300: Loss = 0.040 Acc = 1.00\n",
      "Epoch 132 / 300: Loss = 0.039 Acc = 1.00\n",
      "Epoch 133 / 300: Loss = 0.039 Acc = 1.00\n",
      "Epoch 134 / 300: Loss = 0.038 Acc = 1.00\n",
      "Epoch 135 / 300: Loss = 0.038 Acc = 1.00\n",
      "Epoch 136 / 300: Loss = 0.038 Acc = 1.00\n",
      "Epoch 137 / 300: Loss = 0.037 Acc = 1.00\n",
      "Epoch 138 / 300: Loss = 0.037 Acc = 1.00\n",
      "Epoch 139 / 300: Loss = 0.036 Acc = 1.00\n",
      "Epoch 140 / 300: Loss = 0.036 Acc = 1.00\n",
      "Epoch 141 / 300: Loss = 0.036 Acc = 1.00\n",
      "Epoch 142 / 300: Loss = 0.035 Acc = 1.00\n",
      "Epoch 143 / 300: Loss = 0.035 Acc = 1.00\n",
      "Epoch 144 / 300: Loss = 0.035 Acc = 1.00\n",
      "Epoch 145 / 300: Loss = 0.034 Acc = 1.00\n",
      "Epoch 146 / 300: Loss = 0.034 Acc = 1.00\n",
      "Epoch 147 / 300: Loss = 0.034 Acc = 1.00\n",
      "Epoch 148 / 300: Loss = 0.033 Acc = 1.00\n",
      "Epoch 149 / 300: Loss = 0.033 Acc = 1.00\n",
      "Epoch 150 / 300: Loss = 0.033 Acc = 1.00\n",
      "Epoch 151 / 300: Loss = 0.032 Acc = 1.00\n",
      "Epoch 152 / 300: Loss = 0.032 Acc = 1.00\n",
      "Epoch 153 / 300: Loss = 0.032 Acc = 1.00\n",
      "Epoch 154 / 300: Loss = 0.032 Acc = 1.00\n",
      "Epoch 155 / 300: Loss = 0.031 Acc = 1.00\n",
      "Epoch 156 / 300: Loss = 0.031 Acc = 1.00\n",
      "Epoch 157 / 300: Loss = 0.031 Acc = 1.00\n",
      "Epoch 158 / 300: Loss = 0.031 Acc = 1.00\n",
      "Epoch 159 / 300: Loss = 0.030 Acc = 1.00\n",
      "Epoch 160 / 300: Loss = 0.030 Acc = 1.00\n",
      "Epoch 161 / 300: Loss = 0.030 Acc = 1.00\n",
      "Epoch 162 / 300: Loss = 0.030 Acc = 1.00\n",
      "Epoch 163 / 300: Loss = 0.029 Acc = 1.00\n",
      "Epoch 164 / 300: Loss = 0.029 Acc = 1.00\n",
      "Epoch 165 / 300: Loss = 0.029 Acc = 1.00\n",
      "Epoch 166 / 300: Loss = 0.029 Acc = 1.00\n",
      "Epoch 167 / 300: Loss = 0.028 Acc = 1.00\n",
      "Epoch 168 / 300: Loss = 0.028 Acc = 1.00\n",
      "Epoch 169 / 300: Loss = 0.028 Acc = 1.00\n",
      "Epoch 170 / 300: Loss = 0.028 Acc = 1.00\n",
      "Epoch 171 / 300: Loss = 0.028 Acc = 1.00\n",
      "Epoch 172 / 300: Loss = 0.027 Acc = 1.00\n",
      "Epoch 173 / 300: Loss = 0.027 Acc = 1.00\n",
      "Epoch 174 / 300: Loss = 0.027 Acc = 1.00\n",
      "Epoch 175 / 300: Loss = 0.027 Acc = 1.00\n",
      "Epoch 176 / 300: Loss = 0.027 Acc = 1.00\n",
      "Epoch 177 / 300: Loss = 0.026 Acc = 1.00\n",
      "Epoch 178 / 300: Loss = 0.026 Acc = 1.00\n",
      "Epoch 179 / 300: Loss = 0.026 Acc = 1.00\n",
      "Epoch 180 / 300: Loss = 0.026 Acc = 1.00\n",
      "Epoch 181 / 300: Loss = 0.026 Acc = 1.00\n",
      "Epoch 182 / 300: Loss = 0.025 Acc = 1.00\n",
      "Epoch 183 / 300: Loss = 0.025 Acc = 1.00\n",
      "Epoch 184 / 300: Loss = 0.025 Acc = 1.00\n",
      "Epoch 185 / 300: Loss = 0.025 Acc = 1.00\n",
      "Epoch 186 / 300: Loss = 0.025 Acc = 1.00\n",
      "Epoch 187 / 300: Loss = 0.025 Acc = 1.00\n",
      "Epoch 188 / 300: Loss = 0.024 Acc = 1.00\n",
      "Epoch 189 / 300: Loss = 0.024 Acc = 1.00\n",
      "Epoch 190 / 300: Loss = 0.024 Acc = 1.00\n",
      "Epoch 191 / 300: Loss = 0.024 Acc = 1.00\n",
      "Epoch 192 / 300: Loss = 0.024 Acc = 1.00\n",
      "Epoch 193 / 300: Loss = 0.024 Acc = 1.00\n",
      "Epoch 194 / 300: Loss = 0.023 Acc = 1.00\n",
      "Epoch 195 / 300: Loss = 0.023 Acc = 1.00\n",
      "Epoch 196 / 300: Loss = 0.023 Acc = 1.00\n",
      "Epoch 197 / 300: Loss = 0.023 Acc = 1.00\n",
      "Epoch 198 / 300: Loss = 0.023 Acc = 1.00\n",
      "Epoch 199 / 300: Loss = 0.023 Acc = 1.00\n",
      "Epoch 200 / 300: Loss = 0.023 Acc = 1.00\n",
      "Epoch 201 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 202 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 203 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 204 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 205 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 206 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 207 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 208 / 300: Loss = 0.022 Acc = 1.00\n",
      "Epoch 209 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 210 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 211 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 212 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 213 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 214 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 215 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 216 / 300: Loss = 0.021 Acc = 1.00\n",
      "Epoch 217 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 218 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 219 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 220 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 221 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 222 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 223 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 224 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 225 / 300: Loss = 0.020 Acc = 1.00\n",
      "Epoch 226 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 227 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 228 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 229 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 230 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 231 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 232 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 233 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 234 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 235 / 300: Loss = 0.019 Acc = 1.00\n",
      "Epoch 236 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 237 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 238 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 239 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 240 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 241 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 242 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 243 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 244 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 245 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 246 / 300: Loss = 0.018 Acc = 1.00\n",
      "Epoch 247 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 248 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 249 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 250 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 251 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 252 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 253 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 254 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 255 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 256 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 257 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 258 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 259 / 300: Loss = 0.017 Acc = 1.00\n",
      "Epoch 260 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 261 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 262 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 263 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 264 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 265 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 266 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 267 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 268 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 269 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 270 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 271 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 272 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 273 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 274 / 300: Loss = 0.016 Acc = 1.00\n",
      "Epoch 275 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 276 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 277 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 278 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 279 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 280 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 281 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 282 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 283 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 284 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 285 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 286 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 287 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 288 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 289 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 290 / 300: Loss = 0.015 Acc = 1.00\n",
      "Epoch 291 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 292 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 293 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 294 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 295 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 296 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 297 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 298 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 299 / 300: Loss = 0.014 Acc = 1.00\n",
      "Epoch 300 / 300: Loss = 0.014 Acc = 1.00\n"
     ]
    }
   ],
   "source": [
    "history_classical = train(model_classical, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(model):\n",
    "    with torch.no_grad():\n",
    "        input_sentence = training_data[0][0]\n",
    "        labels = training_data[0][1]\n",
    "        inputs = prepare_sequence(input_sentence, word_to_ix)\n",
    "        tag_scores = model(inputs)\n",
    "\n",
    "        tag_ids = torch.argmax(tag_scores, dim=1).numpy()\n",
    "        tag_labels = [ix_to_tag[k] for k in tag_ids]\n",
    "        print(f\"Sentence:  {input_sentence}\")\n",
    "        print(f\"Labels:    {labels}\")\n",
    "        print(f\"Predicted: {tag_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  COc1ccc(N(C)c2nc(N(C)C)nc3ccc([N+](=O)[O-])cc23)cc1\n",
      "Labels:    CNC.COc1ccc(N(C)c2nc(Cl)nc3ccc([N+](=O)[O-])cc23)cc1\n",
      "Predicted: ['CNC.COc1ccc(N(C)c2nc(Cl)nc3ccc([N+](=O)[O-])cc23)cc1']\n"
     ]
    }
   ],
   "source": [
    "print_result(model_classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reactions[0])\n",
    "# print(smile_strings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger will use Quantum LSTM\n",
      "weight_shapes = (n_qlayers, n_qubits) = (1, 4)\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "\n",
    "model_quantum = LSTMTagger(embedding_dim, \n",
    "                        hidden_dim, \n",
    "                        vocab_size=len(word_to_ix), \n",
    "                        tagset_size=len(tag_to_ix), \n",
    "                        n_qubits=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 300: Loss = 9.274 Acc = 0.00\n",
      "Epoch 2 / 300: Loss = 9.167 Acc = 0.20\n",
      "Epoch 3 / 300: Loss = 9.059 Acc = 0.20\n",
      "Epoch 4 / 300: Loss = 8.950 Acc = 0.20\n",
      "Epoch 5 / 300: Loss = 8.840 Acc = 0.20\n",
      "Epoch 6 / 300: Loss = 8.729 Acc = 0.20\n",
      "Epoch 7 / 300: Loss = 8.616 Acc = 0.20\n",
      "Epoch 8 / 300: Loss = 8.502 Acc = 0.20\n",
      "Epoch 9 / 300: Loss = 8.385 Acc = 0.20\n",
      "Epoch 10 / 300: Loss = 8.267 Acc = 0.20\n",
      "Epoch 11 / 300: Loss = 8.145 Acc = 0.00\n",
      "Epoch 12 / 300: Loss = 8.022 Acc = 0.00\n",
      "Epoch 13 / 300: Loss = 7.895 Acc = 0.00\n",
      "Epoch 14 / 300: Loss = 7.765 Acc = 0.00\n",
      "Epoch 15 / 300: Loss = 7.633 Acc = 0.00\n",
      "Epoch 16 / 300: Loss = 7.497 Acc = 0.00\n",
      "Epoch 17 / 300: Loss = 7.358 Acc = 0.00\n",
      "Epoch 18 / 300: Loss = 7.215 Acc = 0.20\n",
      "Epoch 19 / 300: Loss = 7.070 Acc = 0.20\n",
      "Epoch 20 / 300: Loss = 6.921 Acc = 0.20\n",
      "Epoch 21 / 300: Loss = 6.769 Acc = 0.20\n",
      "Epoch 22 / 300: Loss = 6.615 Acc = 0.20\n",
      "Epoch 23 / 300: Loss = 6.459 Acc = 0.20\n",
      "Epoch 24 / 300: Loss = 6.300 Acc = 0.20\n",
      "Epoch 25 / 300: Loss = 6.139 Acc = 0.20\n",
      "Epoch 26 / 300: Loss = 5.977 Acc = 0.20\n",
      "Epoch 27 / 300: Loss = 5.812 Acc = 0.20\n",
      "Epoch 28 / 300: Loss = 5.645 Acc = 0.20\n",
      "Epoch 29 / 300: Loss = 5.476 Acc = 0.20\n",
      "Epoch 30 / 300: Loss = 5.305 Acc = 0.20\n",
      "Epoch 31 / 300: Loss = 5.132 Acc = 0.20\n",
      "Epoch 32 / 300: Loss = 4.956 Acc = 0.20\n",
      "Epoch 33 / 300: Loss = 4.779 Acc = 0.20\n",
      "Epoch 34 / 300: Loss = 4.600 Acc = 0.20\n",
      "Epoch 35 / 300: Loss = 4.420 Acc = 0.20\n",
      "Epoch 36 / 300: Loss = 4.239 Acc = 0.20\n",
      "Epoch 37 / 300: Loss = 4.059 Acc = 0.20\n",
      "Epoch 38 / 300: Loss = 3.881 Acc = 0.20\n",
      "Epoch 39 / 300: Loss = 3.705 Acc = 0.20\n",
      "Epoch 40 / 300: Loss = 3.535 Acc = 0.20\n",
      "Epoch 41 / 300: Loss = 3.370 Acc = 0.20\n",
      "Epoch 42 / 300: Loss = 3.213 Acc = 0.20\n",
      "Epoch 43 / 300: Loss = 3.065 Acc = 0.20\n",
      "Epoch 44 / 300: Loss = 2.929 Acc = 0.20\n",
      "Epoch 45 / 300: Loss = 2.803 Acc = 0.20\n",
      "Epoch 46 / 300: Loss = 2.690 Acc = 0.20\n",
      "Epoch 47 / 300: Loss = 2.587 Acc = 0.20\n",
      "Epoch 48 / 300: Loss = 2.495 Acc = 0.20\n",
      "Epoch 49 / 300: Loss = 2.411 Acc = 0.20\n",
      "Epoch 50 / 300: Loss = 2.336 Acc = 0.20\n",
      "Epoch 51 / 300: Loss = 2.268 Acc = 0.20\n",
      "Epoch 52 / 300: Loss = 2.205 Acc = 0.00\n",
      "Epoch 53 / 300: Loss = 2.148 Acc = 0.00\n",
      "Epoch 54 / 300: Loss = 2.095 Acc = 0.00\n",
      "Epoch 55 / 300: Loss = 2.046 Acc = 0.20\n",
      "Epoch 56 / 300: Loss = 2.000 Acc = 0.20\n",
      "Epoch 57 / 300: Loss = 1.955 Acc = 0.20\n",
      "Epoch 58 / 300: Loss = 1.913 Acc = 0.20\n",
      "Epoch 59 / 300: Loss = 1.872 Acc = 0.20\n",
      "Epoch 60 / 300: Loss = 1.832 Acc = 0.20\n",
      "Epoch 61 / 300: Loss = 1.794 Acc = 0.20\n",
      "Epoch 62 / 300: Loss = 1.758 Acc = 0.20\n",
      "Epoch 63 / 300: Loss = 1.722 Acc = 0.20\n",
      "Epoch 64 / 300: Loss = 1.688 Acc = 0.20\n",
      "Epoch 65 / 300: Loss = 1.655 Acc = 0.40\n",
      "Epoch 66 / 300: Loss = 1.623 Acc = 0.40\n",
      "Epoch 67 / 300: Loss = 1.595 Acc = 0.40\n",
      "Epoch 68 / 300: Loss = 1.577 Acc = 0.20\n",
      "Epoch 69 / 300: Loss = 1.604 Acc = 0.20\n",
      "Epoch 70 / 300: Loss = 1.574 Acc = 0.20\n",
      "Epoch 71 / 300: Loss = 1.536 Acc = 0.20\n",
      "Epoch 72 / 300: Loss = 1.534 Acc = 0.20\n",
      "Epoch 73 / 300: Loss = 1.524 Acc = 0.20\n",
      "Epoch 74 / 300: Loss = 1.498 Acc = 0.20\n",
      "Epoch 75 / 300: Loss = 1.475 Acc = 0.20\n",
      "Epoch 76 / 300: Loss = 1.454 Acc = 0.20\n",
      "Epoch 77 / 300: Loss = 1.436 Acc = 0.20\n",
      "Epoch 78 / 300: Loss = 1.420 Acc = 0.20\n",
      "Epoch 79 / 300: Loss = 1.405 Acc = 0.20\n",
      "Epoch 80 / 300: Loss = 1.391 Acc = 0.20\n",
      "Epoch 81 / 300: Loss = 1.377 Acc = 0.40\n",
      "Epoch 82 / 300: Loss = 1.363 Acc = 0.40\n",
      "Epoch 83 / 300: Loss = 1.351 Acc = 0.40\n",
      "Epoch 84 / 300: Loss = 1.338 Acc = 0.40\n",
      "Epoch 85 / 300: Loss = 1.326 Acc = 0.40\n",
      "Epoch 86 / 300: Loss = 1.315 Acc = 0.40\n",
      "Epoch 87 / 300: Loss = 1.304 Acc = 0.40\n",
      "Epoch 88 / 300: Loss = 1.293 Acc = 0.40\n",
      "Epoch 89 / 300: Loss = 1.282 Acc = 0.40\n",
      "Epoch 90 / 300: Loss = 1.272 Acc = 0.40\n",
      "Epoch 91 / 300: Loss = 1.262 Acc = 0.40\n",
      "Epoch 92 / 300: Loss = 1.252 Acc = 0.40\n",
      "Epoch 93 / 300: Loss = 1.243 Acc = 0.40\n",
      "Epoch 94 / 300: Loss = 1.233 Acc = 0.40\n",
      "Epoch 95 / 300: Loss = 1.224 Acc = 0.40\n",
      "Epoch 96 / 300: Loss = 1.215 Acc = 0.40\n",
      "Epoch 97 / 300: Loss = 1.206 Acc = 0.40\n",
      "Epoch 98 / 300: Loss = 1.197 Acc = 0.40\n",
      "Epoch 99 / 300: Loss = 1.188 Acc = 0.40\n",
      "Epoch 100 / 300: Loss = 1.180 Acc = 0.40\n",
      "Epoch 101 / 300: Loss = 1.171 Acc = 0.40\n",
      "Epoch 102 / 300: Loss = 1.163 Acc = 0.40\n",
      "Epoch 103 / 300: Loss = 1.155 Acc = 0.40\n",
      "Epoch 104 / 300: Loss = 1.146 Acc = 0.40\n",
      "Epoch 105 / 300: Loss = 1.144 Acc = 0.40\n",
      "Epoch 106 / 300: Loss = 1.157 Acc = 0.20\n",
      "Epoch 107 / 300: Loss = 1.210 Acc = 0.20\n",
      "Epoch 108 / 300: Loss = 1.180 Acc = 0.20\n",
      "Epoch 109 / 300: Loss = 1.108 Acc = 0.40\n",
      "Epoch 110 / 300: Loss = 1.103 Acc = 0.40\n",
      "Epoch 111 / 300: Loss = 1.103 Acc = 0.40\n",
      "Epoch 112 / 300: Loss = 1.124 Acc = 0.40\n",
      "Epoch 113 / 300: Loss = 1.137 Acc = 0.20\n",
      "Epoch 114 / 300: Loss = 1.092 Acc = 0.40\n",
      "Epoch 115 / 300: Loss = 1.065 Acc = 0.40\n",
      "Epoch 116 / 300: Loss = 1.065 Acc = 0.40\n",
      "Epoch 117 / 300: Loss = 1.058 Acc = 0.40\n",
      "Epoch 118 / 300: Loss = 1.064 Acc = 0.40\n",
      "Epoch 119 / 300: Loss = 1.027 Acc = 0.40\n",
      "Epoch 120 / 300: Loss = 1.018 Acc = 0.40\n",
      "Epoch 121 / 300: Loss = 1.010 Acc = 0.40\n",
      "Epoch 122 / 300: Loss = 1.002 Acc = 0.40\n",
      "Epoch 123 / 300: Loss = 0.994 Acc = 0.40\n",
      "Epoch 124 / 300: Loss = 0.987 Acc = 0.60\n",
      "Epoch 125 / 300: Loss = 0.979 Acc = 0.60\n",
      "Epoch 126 / 300: Loss = 0.976 Acc = 0.60\n",
      "Epoch 127 / 300: Loss = 0.976 Acc = 0.60\n",
      "Epoch 128 / 300: Loss = 0.961 Acc = 0.60\n",
      "Epoch 129 / 300: Loss = 0.960 Acc = 0.60\n",
      "Epoch 130 / 300: Loss = 0.936 Acc = 0.60\n",
      "Epoch 131 / 300: Loss = 0.926 Acc = 0.60\n",
      "Epoch 132 / 300: Loss = 0.918 Acc = 0.60\n",
      "Epoch 133 / 300: Loss = 0.909 Acc = 0.60\n",
      "Epoch 134 / 300: Loss = 0.899 Acc = 0.60\n",
      "Epoch 135 / 300: Loss = 0.890 Acc = 0.60\n",
      "Epoch 136 / 300: Loss = 0.881 Acc = 0.60\n",
      "Epoch 137 / 300: Loss = 0.869 Acc = 0.60\n",
      "Epoch 138 / 300: Loss = 0.895 Acc = 0.40\n",
      "Epoch 139 / 300: Loss = 0.867 Acc = 0.60\n",
      "Epoch 140 / 300: Loss = 0.836 Acc = 0.60\n",
      "Epoch 141 / 300: Loss = 0.818 Acc = 0.60\n",
      "Epoch 142 / 300: Loss = 0.831 Acc = 0.60\n",
      "Epoch 143 / 300: Loss = 0.798 Acc = 0.60\n",
      "Epoch 144 / 300: Loss = 0.832 Acc = 0.60\n",
      "Epoch 145 / 300: Loss = 0.786 Acc = 0.60\n",
      "Epoch 146 / 300: Loss = 0.764 Acc = 0.60\n",
      "Epoch 147 / 300: Loss = 0.798 Acc = 0.60\n",
      "Epoch 148 / 300: Loss = 0.740 Acc = 0.60\n",
      "Epoch 149 / 300: Loss = 0.732 Acc = 0.60\n",
      "Epoch 150 / 300: Loss = 0.772 Acc = 0.60\n",
      "Epoch 151 / 300: Loss = 0.727 Acc = 0.60\n",
      "Epoch 152 / 300: Loss = 0.683 Acc = 0.60\n",
      "Epoch 153 / 300: Loss = 0.671 Acc = 0.60\n",
      "Epoch 154 / 300: Loss = 0.665 Acc = 0.60\n",
      "Epoch 155 / 300: Loss = 0.693 Acc = 0.60\n",
      "Epoch 156 / 300: Loss = 0.636 Acc = 0.60\n",
      "Epoch 157 / 300: Loss = 0.627 Acc = 0.60\n",
      "Epoch 158 / 300: Loss = 0.615 Acc = 0.60\n",
      "Epoch 159 / 300: Loss = 0.615 Acc = 0.60\n",
      "Epoch 160 / 300: Loss = 0.598 Acc = 0.60\n",
      "Epoch 161 / 300: Loss = 0.597 Acc = 0.60\n",
      "Epoch 162 / 300: Loss = 0.575 Acc = 0.60\n",
      "Epoch 163 / 300: Loss = 0.567 Acc = 0.60\n",
      "Epoch 164 / 300: Loss = 0.553 Acc = 0.60\n",
      "Epoch 165 / 300: Loss = 0.544 Acc = 0.60\n",
      "Epoch 166 / 300: Loss = 0.534 Acc = 0.60\n",
      "Epoch 167 / 300: Loss = 0.527 Acc = 0.60\n",
      "Epoch 168 / 300: Loss = 0.518 Acc = 0.60\n",
      "Epoch 169 / 300: Loss = 0.511 Acc = 0.60\n",
      "Epoch 170 / 300: Loss = 0.503 Acc = 0.60\n",
      "Epoch 171 / 300: Loss = 0.496 Acc = 0.60\n",
      "Epoch 172 / 300: Loss = 0.489 Acc = 0.80\n",
      "Epoch 173 / 300: Loss = 0.482 Acc = 1.00\n",
      "Epoch 174 / 300: Loss = 0.475 Acc = 1.00\n",
      "Epoch 175 / 300: Loss = 0.468 Acc = 1.00\n",
      "Epoch 176 / 300: Loss = 0.461 Acc = 1.00\n",
      "Epoch 177 / 300: Loss = 0.455 Acc = 1.00\n",
      "Epoch 178 / 300: Loss = 0.448 Acc = 1.00\n",
      "Epoch 179 / 300: Loss = 0.442 Acc = 1.00\n",
      "Epoch 180 / 300: Loss = 0.436 Acc = 1.00\n",
      "Epoch 181 / 300: Loss = 0.429 Acc = 1.00\n",
      "Epoch 182 / 300: Loss = 0.423 Acc = 1.00\n",
      "Epoch 183 / 300: Loss = 0.417 Acc = 1.00\n",
      "Epoch 184 / 300: Loss = 0.410 Acc = 1.00\n",
      "Epoch 185 / 300: Loss = 0.404 Acc = 1.00\n",
      "Epoch 186 / 300: Loss = 0.398 Acc = 1.00\n",
      "Epoch 187 / 300: Loss = 0.392 Acc = 1.00\n",
      "Epoch 188 / 300: Loss = 0.386 Acc = 1.00\n",
      "Epoch 189 / 300: Loss = 0.380 Acc = 1.00\n",
      "Epoch 190 / 300: Loss = 0.374 Acc = 1.00\n",
      "Epoch 191 / 300: Loss = 0.368 Acc = 1.00\n",
      "Epoch 192 / 300: Loss = 0.362 Acc = 1.00\n",
      "Epoch 193 / 300: Loss = 0.356 Acc = 1.00\n",
      "Epoch 194 / 300: Loss = 0.350 Acc = 1.00\n",
      "Epoch 195 / 300: Loss = 0.345 Acc = 1.00\n",
      "Epoch 196 / 300: Loss = 0.339 Acc = 1.00\n",
      "Epoch 197 / 300: Loss = 0.333 Acc = 1.00\n",
      "Epoch 198 / 300: Loss = 0.327 Acc = 1.00\n",
      "Epoch 199 / 300: Loss = 0.322 Acc = 1.00\n",
      "Epoch 200 / 300: Loss = 0.316 Acc = 1.00\n",
      "Epoch 201 / 300: Loss = 0.317 Acc = 1.00\n",
      "Epoch 202 / 300: Loss = 0.312 Acc = 1.00\n",
      "Epoch 203 / 300: Loss = 0.353 Acc = 0.80\n",
      "Epoch 204 / 300: Loss = 0.300 Acc = 1.00\n",
      "Epoch 205 / 300: Loss = 0.291 Acc = 1.00\n",
      "Epoch 206 / 300: Loss = 0.292 Acc = 1.00\n",
      "Epoch 207 / 300: Loss = 0.285 Acc = 1.00\n",
      "Epoch 208 / 300: Loss = 0.313 Acc = 1.00\n",
      "Epoch 209 / 300: Loss = 0.273 Acc = 1.00\n",
      "Epoch 210 / 300: Loss = 0.273 Acc = 1.00\n",
      "Epoch 211 / 300: Loss = 0.264 Acc = 1.00\n",
      "Epoch 212 / 300: Loss = 0.279 Acc = 1.00\n",
      "Epoch 213 / 300: Loss = 0.260 Acc = 1.00\n",
      "Epoch 214 / 300: Loss = 0.280 Acc = 1.00\n",
      "Epoch 215 / 300: Loss = 0.250 Acc = 1.00\n",
      "Epoch 216 / 300: Loss = 0.249 Acc = 1.00\n",
      "Epoch 217 / 300: Loss = 0.236 Acc = 1.00\n",
      "Epoch 218 / 300: Loss = 0.235 Acc = 1.00\n",
      "Epoch 219 / 300: Loss = 0.226 Acc = 1.00\n",
      "Epoch 220 / 300: Loss = 0.231 Acc = 1.00\n",
      "Epoch 221 / 300: Loss = 0.223 Acc = 1.00\n",
      "Epoch 222 / 300: Loss = 0.237 Acc = 1.00\n",
      "Epoch 223 / 300: Loss = 0.218 Acc = 1.00\n",
      "Epoch 224 / 300: Loss = 0.221 Acc = 1.00\n",
      "Epoch 225 / 300: Loss = 0.204 Acc = 1.00\n",
      "Epoch 226 / 300: Loss = 0.199 Acc = 1.00\n",
      "Epoch 227 / 300: Loss = 0.192 Acc = 1.00\n",
      "Epoch 228 / 300: Loss = 0.188 Acc = 1.00\n",
      "Epoch 229 / 300: Loss = 0.184 Acc = 1.00\n",
      "Epoch 230 / 300: Loss = 0.182 Acc = 1.00\n",
      "Epoch 231 / 300: Loss = 0.178 Acc = 1.00\n",
      "Epoch 232 / 300: Loss = 0.178 Acc = 1.00\n",
      "Epoch 233 / 300: Loss = 0.176 Acc = 1.00\n",
      "Epoch 234 / 300: Loss = 0.187 Acc = 1.00\n",
      "Epoch 235 / 300: Loss = 0.181 Acc = 1.00\n",
      "Epoch 236 / 300: Loss = 0.201 Acc = 1.00\n",
      "Epoch 237 / 300: Loss = 0.172 Acc = 1.00\n",
      "Epoch 238 / 300: Loss = 0.163 Acc = 1.00\n",
      "Epoch 239 / 300: Loss = 0.155 Acc = 1.00\n",
      "Epoch 240 / 300: Loss = 0.151 Acc = 1.00\n",
      "Epoch 241 / 300: Loss = 0.148 Acc = 1.00\n",
      "Epoch 242 / 300: Loss = 0.146 Acc = 1.00\n",
      "Epoch 243 / 300: Loss = 0.143 Acc = 1.00\n",
      "Epoch 244 / 300: Loss = 0.141 Acc = 1.00\n",
      "Epoch 245 / 300: Loss = 0.138 Acc = 1.00\n",
      "Epoch 246 / 300: Loss = 0.136 Acc = 1.00\n",
      "Epoch 247 / 300: Loss = 0.134 Acc = 1.00\n",
      "Epoch 248 / 300: Loss = 0.132 Acc = 1.00\n",
      "Epoch 249 / 300: Loss = 0.130 Acc = 1.00\n",
      "Epoch 250 / 300: Loss = 0.128 Acc = 1.00\n",
      "Epoch 251 / 300: Loss = 0.126 Acc = 1.00\n",
      "Epoch 252 / 300: Loss = 0.124 Acc = 1.00\n",
      "Epoch 253 / 300: Loss = 0.122 Acc = 1.00\n",
      "Epoch 254 / 300: Loss = 0.120 Acc = 1.00\n",
      "Epoch 255 / 300: Loss = 0.119 Acc = 1.00\n",
      "Epoch 256 / 300: Loss = 0.117 Acc = 1.00\n",
      "Epoch 257 / 300: Loss = 0.115 Acc = 1.00\n",
      "Epoch 258 / 300: Loss = 0.114 Acc = 1.00\n",
      "Epoch 259 / 300: Loss = 0.112 Acc = 1.00\n",
      "Epoch 260 / 300: Loss = 0.111 Acc = 1.00\n",
      "Epoch 261 / 300: Loss = 0.109 Acc = 1.00\n",
      "Epoch 262 / 300: Loss = 0.108 Acc = 1.00\n",
      "Epoch 263 / 300: Loss = 0.106 Acc = 1.00\n",
      "Epoch 264 / 300: Loss = 0.105 Acc = 1.00\n",
      "Epoch 265 / 300: Loss = 0.104 Acc = 1.00\n",
      "Epoch 266 / 300: Loss = 0.102 Acc = 1.00\n",
      "Epoch 267 / 300: Loss = 0.101 Acc = 1.00\n",
      "Epoch 268 / 300: Loss = 0.100 Acc = 1.00\n",
      "Epoch 269 / 300: Loss = 0.099 Acc = 1.00\n",
      "Epoch 270 / 300: Loss = 0.098 Acc = 1.00\n",
      "Epoch 271 / 300: Loss = 0.096 Acc = 1.00\n",
      "Epoch 272 / 300: Loss = 0.095 Acc = 1.00\n",
      "Epoch 273 / 300: Loss = 0.094 Acc = 1.00\n",
      "Epoch 274 / 300: Loss = 0.093 Acc = 1.00\n",
      "Epoch 275 / 300: Loss = 0.092 Acc = 1.00\n",
      "Epoch 276 / 300: Loss = 0.091 Acc = 1.00\n",
      "Epoch 277 / 300: Loss = 0.090 Acc = 1.00\n",
      "Epoch 278 / 300: Loss = 0.089 Acc = 1.00\n",
      "Epoch 279 / 300: Loss = 0.088 Acc = 1.00\n",
      "Epoch 280 / 300: Loss = 0.087 Acc = 1.00\n",
      "Epoch 281 / 300: Loss = 0.086 Acc = 1.00\n",
      "Epoch 282 / 300: Loss = 0.085 Acc = 1.00\n",
      "Epoch 283 / 300: Loss = 0.084 Acc = 1.00\n",
      "Epoch 284 / 300: Loss = 0.084 Acc = 1.00\n",
      "Epoch 285 / 300: Loss = 0.083 Acc = 1.00\n",
      "Epoch 286 / 300: Loss = 0.082 Acc = 1.00\n",
      "Epoch 287 / 300: Loss = 0.081 Acc = 1.00\n",
      "Epoch 288 / 300: Loss = 0.080 Acc = 1.00\n",
      "Epoch 289 / 300: Loss = 0.079 Acc = 1.00\n",
      "Epoch 290 / 300: Loss = 0.079 Acc = 1.00\n",
      "Epoch 291 / 300: Loss = 0.078 Acc = 1.00\n",
      "Epoch 292 / 300: Loss = 0.077 Acc = 1.00\n",
      "Epoch 293 / 300: Loss = 0.076 Acc = 1.00\n",
      "Epoch 294 / 300: Loss = 0.076 Acc = 1.00\n",
      "Epoch 295 / 300: Loss = 0.075 Acc = 1.00\n",
      "Epoch 296 / 300: Loss = 0.074 Acc = 1.00\n",
      "Epoch 297 / 300: Loss = 0.074 Acc = 1.00\n",
      "Epoch 298 / 300: Loss = 0.073 Acc = 1.00\n",
      "Epoch 299 / 300: Loss = 0.072 Acc = 1.00\n",
      "Epoch 300 / 300: Loss = 0.072 Acc = 1.00\n"
     ]
    }
   ],
   "source": [
    "history_quantum = train(model_quantum, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  COc1ccc(N(C)c2nc(N(C)C)nc3ccc([N+](=O)[O-])cc23)cc1\n",
      "Labels:    CNC.COc1ccc(N(C)c2nc(Cl)nc3ccc([N+](=O)[O-])cc23)cc1\n",
      "Predicted: ['CNC.COc1ccc(N(C)c2nc(Cl)nc3ccc([N+](=O)[O-])cc23)cc1']\n"
     ]
    }
   ],
   "source": [
    "print_result(model_quantum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_history(history_classical, history_quantum):\n",
    "    loss_c = history_classical['loss']\n",
    "    acc_c = history_classical['acc']\n",
    "    loss_q = history_quantum['loss']\n",
    "    acc_q = history_quantum['acc']\n",
    "    n_epochs = max([len(loss_c), len(loss_q)])\n",
    "    x_epochs = [i for i in range(n_epochs)]\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.plot(loss_c, label=\"Classical LSTM loss\", color='orange', linestyle='dashed')\n",
    "    ax1.plot(loss_q, label=\"Quantum LSTM loss\", color='red', linestyle='solid')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.plot(acc_c, label=\"Classical LSTM accuracy\", color='steelblue', linestyle='dashed')\n",
    "    ax2.plot(acc_q, label=\"Quantum LSTM accuracy\", color='blue', linestyle='solid')\n",
    "\n",
    "    plt.title(\"Part-of-Speech Tagger Training\")\n",
    "    plt.ylim(0., 1.1)\n",
    "    #plt.legend(loc=\"upper right\")\n",
    "    fig.legend(loc=\"upper right\", bbox_to_anchor=(1,0.8), bbox_transform=ax1.transAxes)\n",
    "\n",
    "    plt.savefig(\"pos_training.pdf\")\n",
    "    plt.savefig(\"pos_training.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_classical, history_quantum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function decreases as a function of the training epoch, and after 300 epochs both networks are able to tag correctly the first sentence. Due to the complexity of the simulation of the quantum circuit, it took approximatively 15 minutes to finish the training, to be compared to a mere 8 seconds for the classical case. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d4e8c657857f8450e5ea1dd61e524b6df2be80a0331bd50c0d2e4e3fe46c7a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('QLSTM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
